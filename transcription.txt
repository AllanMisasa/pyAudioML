 Hey everyone. Hi everyone. So, I know last year I wound up talking for three and a half hours and over running some of the tournament broadcasts. So we're going to, the idea was to attempt to shorten it down a little bit. But when I went and took notes for myself about all the things that I wanted to talk about, there was like 300 lines. So we'll see what happens. Tim will probably cut me off if I wind up running too long. So there's an amazing amount of exciting things going on in technology now that affect gaming and the larger ecosystems that we work in. And a lot of it's just fascinating in so many ways. But the thing this year that's sort of the elephant in the room that we can't go without talking about is the console cycle, where we went a lot of years with the same console platform. And it was good for developers and console players. But it was, if anything, getting a little bit stale considering how long it had lasted relative to previous generations. And now we have the heavy hitters with Microsoft and Sony coming out. Now obviously I'm still under NDA and I can't talk about really juicy technical details. But there's enough out in the public record that there can be some discussion about it. And it's, you know, it's interesting, it's almost amazing how close they are in capabilities, how common they are and that the capabilities that they give are are essentially the same. We can talk about differences in memory architectures, but the bottom line being that they're a multi core AMD processor with AMD graphics is it's almost weird how close they are. Where I'd love to know the back room stories between the different companies about who knew what when about how close they were coming together, whether they converged intentionally or if they were just surprised that they wound up having almost identical specs. So in the near term it's clearly going to be a good thing for developers, gamers, an excellent thing for AMD. We know we've got, it's really interesting considering three or four years ago when we were looking at where we thought the next console generation was going to go. At the time we were really thinking that there was a possibility that we might wind up with in all the Intel world where Intel with Larabi as their CPU oriented GPU might go out and push really hard on the console vendors and maybe even sweep the field. You know there was a thought that Intel has resources that almost no other company has. They have certainly the best process technology, they have some of the very best silicon engineers and they've got boatloads of money that if Intel wanted to go in and make a mark here that they might go in and potentially even buy the winds to make offers that the vendors couldn't refuse. Larabi was very interesting when you looked at it as something that was different than the CPU talking to the GPU world that we've had for a long time now. It would have opened up the possibility for some novel rendering architectures for sort of reinventing the wheel and making it look a little bit different. Things like voxel or splatting architectures and some of these things that are not triangle rasterization based might have been better suited there. But as we all know by now Larabi was eventually dropped as a GPU product. I know some of the people that worked on the project and a lot of the hardware people will just say, oh it just wasn't quite ready because of the software but the hardware was good. The hardware does live on as a high performance computing part in the Xeon Phi. But still that thought that several years ago we thought it might all go this way and it went almost diametrically opposite direction. We could have wound up with still a fragmented world like we've had for every console generation where different vendors have different architectures and approaches and developers are forced to choose the common subset between what the different platforms can do which always leads to less optimal development and less your sole platform, single platform game on a console where you can really optimize for that you're always making compromises. And on the PC you're always making compromises across the breadth of your installed base. But now we did wind up with something that looks like, again a PC based architecture. AMD has, they've traditionally lagged Intel and raw performance on the CPU side but having a lot of cores here having it something that's going to be prevalent on the consoles means that developers will favor that as an optimization and that will give AMD a little bit of a boost relative to Intel clock for clock probably. I mean you'll optimize the code specifically for one micro architecture and that will probably become somewhat prevalent on the PC. Intel still has a significant enough performance lead that I don't think they'll outstrip them in raw performance performance but it will help close the gap and makes it useful when you're comparing price performance and some of the other things there. So in the near term it's clearly a good thing for gaming. In the longer term we can maybe worry a little bit about whether a monoculture in the ecosystem there is really a good thing. I suspect that we're at a mature enough point in game development that it's probably not particularly harmful that making radical different changes are so traumatic that we can coast for quite a while without having to really fundamentally reevaluate the things that we're looking at. But it still could have gone differently. We could have wound up with another real player for real content for, contestant for console generations would have been super mobile hardware rather than kind of productized PC hardware. We can imagine something that had maybe 16 arm cores with a whole bunch of power VR graphics cores and you could have made a pretty good console with that. There's a lot of, there's a big ecosystem for that. There's a ton of development work going on. You get good easy performance out of them in a lot of ways. And I suspect it was the 64 bit not being quite cooked enough on there that really made the difference. And the fact that huge amounts of memory are obviously a big deal for the console platforms now. And that's probably even more so than the last factor of raw performance. Tons and tons of memory is the thing that makes game development a lot easier. I mean, we are currently going through the crunches to make Wolfenstein fit on existing platforms. And it's that, you know, it's always that final 90% when you think you're done with the first 90% of the development. It's the last 10% that turns out to be just about as much work to make it all work inside the limited resources. So lots of memories going to be nice on the upcoming consoles. It's going to make things a little bit easier. There's a ton more that we'll do visually and I to the games there. But I think that I think that the writings on the wall that pushing things to their absolute limit is not really tenable for the most part in development. Because there's just too much that you can do. It was one thing when you had a system that you could sort of hold the entire reference manual in your hand. And you could say, well, we're going to do as close to the absolute best we can imagine as possible on this. But, you know, nowadays no one person even has the entire capabilities of one of these modern platforms in their head. You wind up specialists in, you know, the SIMD code and the compute code and the GPU and the memory architectures. In the file system, the user experience, the interfacing with the operating system. All these things, there's too much to wind up with this crystal jewel of perfection. Like you might have at least deluded yourself into thinking you were approaching in previous years. So development is a lot more about trying to get the good value out of the time that you can put into it. And mobile has really been like that for a while now. Most mobile developers are not anywhere close to trying to max out what they can do on their diverse ecosystems and platforms. It's really about trying to come up with something fun, make it happen, and iterate it on it quickly. And that's, you know, there's a part of me that always is, you know, always does want to do the absolute best possible. But the reality is that's just not the smart play to, you know, to look at the modern game systems. And we've got the comparing the two big players right now. I mean, what we should first say that the other bit players, it's interesting to look at where the Wii U, I always thought that the Wii U and the Vita would be great targets for doing through BFG. We know we should be able to bring that over directly, but it's not something that's generating enough interest on the publishing side of things. Because it's just, there's somewhat marginalized platforms and looking at the adoption of them. It's certainly got to be a little scary even for the mainstream consoles, for the big ones, whether there will be the relaxed expectations of what they can move through on there. I mean, clearly there's a difference on the handheld platforms being in the post-smartphone world. While the 3DS is doing okay, the Vita is really not doing particularly well. And a lot of that has to come from the fact that we have not quite as good gaming platforms, but everybody's carrying a pretty good gaming platform already, telling a new one into there is a little bit of a harder sell. But the smartphone developments on there are going to certainly matter about how you approach development, how you look at the different platforms that you support. But the big two are clearly coming out with both barrels loaded, and they're going to have a big impact. It's going to be very, very interesting to see how it goes over the next couple years, if they meet the adoption of the previous ones, or if something is fundamentally changed in the market. Now, everyone would like me to come out with some A over B comparison about the two platforms. And to be completely honest, I haven't done really rigorous benchmarking on them, so even if I didn't have NDA protection, I couldn't give you a really completely honest answer. But they are very close, they're both very good. So, it's no secret that in the previous generation I favored the 360 over the PS3. While there are certain things that Sony did well for a game developer, the 360 was a nicer platform to work on. It was a little bit more powerful, it had much better development tools, and it just felt better. Sony has made large strides. Their development tools came out of the gate much, much better than they ever have. They've made somewhat more gamer focused decisions in their strategies and architectures. Microsoft is putting a lot behind things like connect that I'm still not really sold on connect. I recognize that what my needs and desires as a game developer, or what I use the technology for, might not cover the broad consumer base that they're looking for. So, it's there play to make, but I think connect still has some fundamental limitations with the latency and the frame rate on it. And interacting with it is still, when you interact with connect, some of the standard modality interactions there about like position and hold and position, waiting for different things. It's fundamentally a poor interaction, and one way that I look at it is I used to give Apple a lot of grief about the one button mouse when anybody working with a mouse really wants more buttons are helpful there, and connect is sort of like a zero button mouse with a lot of latency on it. Where I am. Where you move around and you select something, but because you can't snap your finger at it and make something happen, you have to wait for a time period or have some other trigger section there. And things like the PS move where you're maneuvering around and you actually got buttons on it, or something like the Sixth Sense Razor Hydra where you got position tracking, but also buttons to click. I think have some fundamental advantages. Now it's possible that as we get finer and finer grain control of the tracking that maybe you can start telling, you know, intentional little taps of the finger in virtual space. And that will, you know, that will help some of it, but I'm still not completely sold on it. The other thing with connect is that relative to touch, which has been a revolution in user interface, and it's just, it's absolutely amazing to watch a two year old play with an iPad and just have things moving around. And that was clearly such a huge win where that is a big, big positive to user computer interactions because you're directly manipulating things. Now connect as far as waving your hands around and moving things, it is still at least a directly proportional interface like a mouse where you can say I'm moving six inches here and it's going to be proportional that six inches of moving, which puts it into a better category than analog thumbsticks where you're integrating your motion over time. But you're not directly manipulating things because you're moving your hand here, but you're watching the screen over there to see what's happening. Now it's possible that you could have, if you had a viewer relative game, if you weren't using connect as sort of your social party game where multiple people are playing. And at the same time, you were looking at a screen and you tracked where the viewer's eye was and you knew where their hand was in perspective space. You could then sort of do, okay, I'm touching that, I'm moving that over there. You would still have all the latency issues to deal with there, but it would be a much more direct interface. And things like body tracking like that will have more, more benefit when you've got things like a virtual reality system where you can see your rendered virtual hand interacting with rendered virtual things. So it's a technology that absolutely has a future and Microsoft is pushing it hard. They've done a lot of excellent research with it, but I'm still not completely convinced that that's the cornerstone of the next gaming platform. But they're still doing all the other things that they've done well right. So they are a solid force to be contended with no matter what. But it's anyone's game as far as I can tell right now, and that's exciting. I think that we're always healthiest with at least a strong duopoly, if not a full three vendor sort of three vendors fighting it out. So the game development on there, it's not changing as much as you might think going from previous generations. We have our ways of doing things, and because it is a conventional approach that's not tearing up the rule book, most studios are pretty much evolving the code that they've got. You are not throwing away our couple million lines of code and doing something completely different. It is still using your cores to run code, to generate vertexes, and run fragment shaders on it. And that's not changing all that much. You just get lots more of everything. And I again think that most of the time a lot of it will be spent on just making our lives easier so we can do a better job with the games. So some of the things like community backlash against the Xbox One, it was interesting to see the power of the public reaction on it. And there's a couple things that have played into the public consciousness on it. One of the things that was up early before even the major issues with the used games and always on and things like that was people being a little bit freaked out about connect being on all the time. And this my game system is going to be watching me at all times and who knows what that can do. And I had a lot of conversations with people that really just didn't think that was right, that that feels incorrect. I am completely confident that that's a very temporary sort of vision about things where if we go back ten years, the idea that everyone would be carrying around a phone that has your GPS located position at all times would cause a lot of the tinfoil hat crowd to go after that. The idea that the government is going to have back doors into all of these, they can turn them on and track everything where you're going. And well, yeah, that's pretty much the situation, but we just kind of carry on. The situation with connect, there's already a ton of laptops where the webcam is there and you have issues with people remote hacking things and turning them on. And I wouldn't be surprised if there's not some absolutely terrifying hack that happens at some point that is a huge media issue with it. But we'll just get used to it. A lot of these things are inevitable. Like the people talking about Google Glass and the issues with people carrying around having cameras, recording things all the time. I think that's going to be a net positive for society having this sort of ground truth that's that's retrievable in many cases in a lot of things. But it is it does have sort of social transition issues that we're going to have to feel through as those are adopted. But there's there's a tide of technology that I think is in many cases stronger than I you know than what even regulations can hold back in a global world where you can have sort of local places where you'll have. stronger privacy regulations, stronger you know, preventions of like I guess in some European countries you can't leave the devices on all the time. So Xbox certainly will not be required to operate in that mode. You can turn it off. But they have a vision for how it's going to interact with you. And we don't know yet. It's people have to try these things to find out if they're really going to be good. The thing that of course got Microsoft the most in most hot water was the issues with always internet connected being able to not having the use game transfers that whole issue. And I do sort of fall onto the side of I think the witch hunt was a little bit unjustified there. There are legitimate grievances that people can raise about how they would choose to have you know their game systems managed. I personally am extremely fond of having all of my digital purchases in a curated garden all of the all of my iTunes all of my Amazon stuff all my Steam things. And that's it's a positive thing. I mean yeah you can have better and worse ways of doing that. But we are very quickly going to be past the age of having a game that you hold in your hands on optical media. I think that was another thing that was open for debate this generation was were we going to have optical media at all or was it going to be all digital distribution. I would it's probably won't be many years before we wind up with skews that just have the optical drives deleted. And everybody will just be getting it through the net. I think that's again a clear case of the future is the future is obvious right there and it will be good for us in general. I go over this a lot with books where I'm sort of a bibly of file where I love books. I love my I have an encyclopedia Britannica set that I hardly ever open all these things where we have a fondness for our our physical. The fetishes of the objects that we bought but really it is just so much better having everything in the cloud and being able to get at it like that. Now the other platforms that I'd love to be able to develop on 3DS and some of the other other things other small platforms I would like to see the game show up on the Vita or the Wii U. just to kind of play with some of the different characteristics that they've got there. But it's it's extremely unlikely to happen because there are there's a finite amount of time and there's only so many things that you can focus on. And there's you know the fact that you can't be you can't have complete knowledge of even one of these platforms even the handhelds now have so much going on on them. If you know all of the interest of the arm instruction set and there different extensions and the characteristics of the GPUs and the different memory mapped I.O. registers there. even that's getting to be a little bit too big for somebody to you know to get a full grasp of or what happens is you're just finally getting the hang of everything five years into it when the console cycle changes again. And I can look right now with some fondness at the 360 in the PS3 and say we've got a really good handle on this we can we can do some great stuff in it but it's time to put that aside and go on to the you know the next generation where we're still groping around figuring out what's you know what's going on. One of the other direction other platforms that is in my opinion not going to be making a big impact right now is the sort of micro consoles where you look at the OIA's and the things that are just tiny little things that plug into your TV. In the long term it's it's possible that things like that may become very very important as they're coupled with cloud rendering and the distribution like that. I don't think that it's going to have a super big impact right now but it is amazing to see how the relevance of Android has the title wave of Android just pushing almost everything else out of its way. I'm still obviously an iOS user for most of my day to day stuff but I did finally just in recent weeks spin back up a little bit on Android development where I looked at it three years ago and I thought it was really pretty awful. But it's especially compared to Apple but you look at pieces of relative change and Apple continues to make things better but you know Google has made things better at a faster rate to the point where developing like a Java app on Android is really not that bad right now. You download their the ADT bundle and you plug in your device and it pretty much just works in many ways without the certification hassles of iOS some things like that can actually be a lot easier. It's only when you get into the native development kit that things really fall apart in terms of not not really looking well cooked at all. But when you look at the scope of Android and what they've done it's the power of free. There's giving away the platform has been such a good thing for the entire sort of electronics industry because if we look back five years ago we had every little handset company trying to write their own operating system essentially and doing a very very bad job at it. I mean now we still have the danger that everybody they go take Google's code base and they mess it up in various ways while adding value. We've got that classic problem of that's happened with video card drivers in the battle days and it certainly happens with Android platforms now but it's still worlds better than we would have been if they had to be rolling it by themselves. So that's been a great thing it still has you know it has a lot of the messiness of Linux underneath it I mean that's still what's down there in the development tools reflected but there's also some of the magic of it where when I'm poking through something and I realize it's like okay this is going into the system library. Oh I can just go get the whole source code for Android dot jar and I step in through that and then I can look at the kernel drivers for at least the reference implementation of things. So that's you know that's pretty wonderful it's you know it's not clear when I'll have an opportunity to do iOS development again to do a fair comparison but the taking things in three year gaps is great to see progress where when you're sitting just kind of sitting with it you might not notice how much better things have been getting. But the Android stuff looks you know looks at least usable now I so we've got things like Nvidia shield which is certainly basically a repackaged super smart phone in a high quality handheld gaming format. And that's you know it's pretty neat on there it's got excellent ergonomics and good controls for it it's not just a really crappy Bluetooth game pad bolted onto a phone. You can still see some of the warts of Android sort of showing through like I was playing Sonic on it and you know Sonic is not supposed to drop frames that's sort of the essence of what the Sonic the Hedgehog experience is about and you do get an occasional stutter that I would delay the blame at Android and you can go when you 80 B into an Android system and you do a PS and you look at pages of stuff scrolling or scrolling by like what is all this crap and how is it helping make my experience better. It's a shame that that's not more nailed down now some of the problems maybe not just scheduling but also the drive for power management where you think that if you have a quad core mobile system that we could just be saying well let my game use two of those cores put nothing else on there and just let me be like on a console and have things where they schedule and you wake up in a fraction of a millisecond. It just doesn't work out that way you can have four millisecond difference in you know when you wind up waking up the next time and I'm still new enough to all of this I don't have the answers at the bottom of it but the you know the platform is not. You know it's not as much as you could hope for and while it's all solvable you can certainly look down and say well what do we need to do at the kernel level what do we need to expose to make this better. I unfortunately probably won't get solved like that a little eventually be solved by just a complete sort of it of extra resources. You know maybe when we have 16 core arm processors we can actually have eight of them to our self and you know and let all the other stuff kind of use up the other processors. And that's sort of what the I. You know what Microsoft and Sony are doing on the big platforms is reserving processors for the other stuff they want to do. And as a game developer if we know okay we've got you know five six seven whatever cores that are really ours we can work with that and we would rather work with that than having kind of random unknown things popping up and bothering us. You know cloud gaming again I've been saying this for years I think it will have a big impact and while you know I online hasn't set the world on fire for anything. Things are still progressing it's again people will look at bandwidth or latency and think it's not getting good enough fast enough but years go by and things just get a whole lot better. You know we have a ton of bandwidth coming to a lot of houses now and while it's not everywhere just like you don't expect to be able to play your Xbox in the car. There will be places where cloud gaming is just not appropriate. When you're backwards cabin with the satellite internet link not going to be a good idea but there's going to be plenty of places where it's going to be practical and it's going to offer really strong advantages for the consumer. Being able to kind of pop in and out of all of your games as fast as you switch web pages being able to architect games for huge back-end clouds that could take care of resources where it never even has to go to flash it's always swapping from somebody else's ram in the cloud. Being able to have completely fair network play without any local prediction being able to run them essentially a split screen with people in multiple places. There's a lot of advantages there and I think that there is a, I would bet that there will not be another console generation like this where we think about the Microsoft box, the Sony box after this one. This one's going to last this generation is going to last a long time and I think it's likely that some combination of mobile devices, generic players, cloud streaming and some other devices will wind up sort of fragmenting that around. A lot of different front and back ends rather than having the platform that's being developed on but you know whether that's basically you'll have to come back in probably eight years from now to see whether that prediction comes true because this console generation is going to have a lot of legs to it. So we've got all this power now that we've got on the PCs, you know what you can put in multiple titans into a PC box and render just absolutely incredible amounts of flops and vertexes and textiles. So what do we want to do with it? I think that the most important thing is trying to make the game development faster and easier more iterations on creativity because I do think that we are fundamentally creativity bound at this point. So if you look at some fabulous blur game trailer that's made to just make something look unbelievable, the state of the art and offline rendered graphics and they look pretty sweet. You know there's amazingly good stuff there but a lot of what's amazing in game trailers is the director's view. It's the scripting in the layout of what's happening there. Something that I would love to see and it would be expensive and I know what he's probably going to do this to satisfy idle curiosity but I'd love to see somebody take just a random snippet of someone's game. Just you're playing this game. Let's just take five minutes somewhere midway through your game and give it the full offline rendered trailer treatment on there. And if you said if we just applied unlimited graphics power, how much better would the game experience be? And I suspect not all that incredibly much. We can already do a credible job of rendering anyone's creative vision in the game. We still avoid some of the hard cases, some of the things that don't come out really well. We're not going to do a ton of furry creatures and deformable, triple worlds and things that are still kind of hard. But we can do a good job at anything that a creative director can say, this is going to be the greatest game ever. Help me draw it on the screen. We can always make things a lot better. There's a lot of advances going on. There will be continuous improvements but it's not going to be set the world on fire that this is the game that you have to buy because the graphics are prettier. There are a lot of things that we should stop putting up with though, things that we are sort of used to. It's a pause me that we still have people that are targeting 30 Hertz games for next generation. It's not bad hard. It was hard to hit 60 on the current generation. There are scars in the code base and on the developers that let us make it to the quality and performance level that we did. We've got a lot more power now. Yes, you can throw at it doing some crazy pixel shader to get some final little bit of physically correct lighting on the screen of the pixels. It's going to be lost in the difference in non-calibrated color between people's TVs. I think it would just be much better for people to concentrate on smoother game experiences. I see this where you see somebody talking about a very advanced rendering technique talking about subtle differences in the specular lobes of the BRDF of this material. There's a demo going with a tear line flying up and down the screen where this is just not a priority is out of whack. We do get tunnel vision on our own little thing. The graphics programmers as a whole and then rendering people in specific there. But stepping back and looking at the whole thing, we should have complete consistent frames presented. We shouldn't have a tear jumping around. A problem with that is that it means that you are limited to these nocchi frame rates, 30, 60, 120 in some cases. And it means that it's harder for performance, subtle performance differences to show. I mean benchmarking is all about do you get 32 or 47 frames per second? And if you're playing the frame rate game properly, the locked frame rate, that's not a valid distinction between them. Maybe you start doing like we do with resolution scaling, but it takes away one of the bragging rights things. That's sort of always the fun of the PC gaming rig culture of just the hot rotting for the modern days. But it's not necessarily in the best interest of the full gaming experience rather than just throwing more of a die. A little further over. We see a lot with some of the graphics things that we still have DXT compressed textures that turn a lot of things into garbage. And it doesn't matter what you do with the fragment shader there, if you garbage in, garbage out. But even if you step back a little bit more where the normal maps that we use for everything are everybody bakes 8-bit normals. And interestingly, even with the first GeForce that supported sort of normal mapping, Nvidia recognized that 8-bit normals really aren't good enough, and they had the 16-16 high-low format to have, like if you want to do a smooth compound curve like an auto body, you can't use an 8-bit normal map on it. That's referenced in global space. It's just not good enough. So making some of these transitions were okay. We've got a lot of memory. Now we can just stop doing some of these things that we're so used to. Use some more uncompressed textures. Don't use certain formats. Getting to gamma correction for everything and a lot of these things that will make subtle differences. But they're not going to change the face of gaming. These are things that it'll make gaming better, but it's not going to be something on the level of some of the breakthroughs that we've seen in the last couple decades. As we got our first 3D experience, our first 6-degree of freedom experience, as we moved to GPUs in the first place and started taking some of those strides. I honestly don't think that there is another stride of that level really left. Eventually, we will get to fully physically-based ray-traced rendering. It's not coming in this generation, but it's coming eventually, and it will win in the long term. I think there's almost no argument against it. And it'll be great. It'll be better than what we've got, but won't change the world. Some of the things like that we still see funny and graphics engines when you're doing super sophisticated things. Animation, looking at games and you see something that's gorgeously lit, local, subsurface scattering and everything. You see a box on something just slide right through an arm or all this inner penetration of things that are blatantly engrossally unrealistic. You can say, oh, but my light transport is on the nose. But when the simulation of what's actually going on is completely off your... It's not the full experience that you're expecting there. So a lot more work has to be done with that to go ahead and make simulation of things better, to make presentation of human and animation, all these different things to climb completely out of the uncanny valley and all conditions. There's tons and tons of work to do there. And I think that the things that will make the largest differences probably won't be in exactly the pixel rendering. I still love it. I'm going to talk a lot about it tomorrow on where we... those final things that we do need to do to get to really, really correct and right pixel rendering the physics of it, what we can change. But it's not going to really radically change the scope of the gaming. So the GPUs that are giving us all this power, we probably will be able to use more and more of it for things that aren't graphics rendering, being able to use it for the simulations. And there's been, you know, for a decade now, people have been talking about, well, we're going to be able to use this stuff to make better and better physics or better simulations of different things. And it's been troublesome because you can't make physics a fundamental aspect of the game and make it optional or scalable. It just doesn't work out that you could have a low-end system have slightly different physics solvers. So all we really get to use that for is cloth. You know, you get your cloth waving in the breeze, your grass, and your water surfaces. And all that's great. We'll get a lot more power from it. So faster and faster GPUs are still a good thing even if you believe that we're past the need of the benefit curve for pixels. All this power will still get used for useful things. And there may be some tipping point where we cross a threshold and we really can do something that's important and magnificent that just wasn't possible before. I don't really... I don't have a suggestion for that, but it's going to be the things that people don't expect. Where at some level of power and simulation fidelity we're able to do something really cool. So the GPUs, one of the trends that's going on now that the consoles are thankfully going to be leading the way on this is the unified memory. PC, ad in graphics cards are very much swimming against the tide of history. Separate memory buses are the way things have been on graphics for, you know, since the beginning. There's a lot of reasons why that's not a very great thing. We're having to send things across the bus, having to manage separate memory spaces. We had to deal with that on the PS3 with the split memory architecture. And life is just much, much better when it's all unified. Intel is obviously bullish on this with their integrated parts, but there's a resistance from Nvidia. They have their stranglehold on the super high end workstation class separate ad in cards. And they don't have as strong of a position with integrated parts. So they cater to their interest, but leveraging the unified memory space is going to be where a lot of the advances in development interaction with the GPUs goes. Where we should be treating the GPUs just like another processor. We have, we talk with four or eight or however many cores of CPUs. We work out our scheduling systems. Sometimes we do have our critical sections and our locks and the things we have to live with on there. Right now with graphics, that's pretty much hidden behind an opaque graphics driver layer. Where we need to get to the point where we can treat the drivers, we can treat the GPUs the way we treat the other CPU cores. And that's going to involve the vendors giving up some of their flexibility. And that's a hard, hard fight. Where right now textures are still an opaque blob and each vendor has their own way of organizing them. But forces are battling this where we have, you know, everybody has to support native formats. Everybody has to be able to render to a texture from them for, you know, for the Android platform, if nothing else, for the compositors, for running on, you know, whatever you're doing with windows in the Mac. So we have to have this generality at least at that level. But I am, I've been calling on them to document and expose all of their, you know, the more texture format you want to use, the tiled and swisled formats. Because there's a lot that we can do to make things better. Right now it's, like, it's especially pathetic on Android. If you want to load a texture in on Android, you wind up loading it into Java, making a native buffer, passing that native buffer to the driver, which will copy it into some other place that maybe will be GPU-related. And you've got at least three steps going through here. And what my vision for the future of a lot of asset management is, oh, this should just be memory mapped into 64-bit address space. It's all going to be backed by Flash. We're not going to have this 15 millisecond rotational latency to deal with. But to be able to back something with the memory map file, we need to know exactly what the data looks like. So we need to know what these formats are. We need to know what limitations there are on tiling and alignment and so on. So this is one of my big pushes. I want to see this happen. I think it makes too much sense for people to, you know, really argue against a side from strictly parochial concerns about the, you know, your add-on card won't be able to do this as efficiently if it's going over PCIe, whatever. But that's, it's something, it's a path that we will be evolving to that will make everything better enable a lot tighter interactions. It'll be a good thing. So the virtualization of graphics resources finally sort of hit mainstream now with the tile textures and tile resources. And this is something that people that have been coming here have been hearing me, bitumen about this for 12 years or something. It's finally in hardware that a lot of you own. It's still not what it should be because interactions with the operating system are hamstrings things. Where I come back to this, I really want this, please memory map this file, you know, please let me, you know, page things out. And some of this battle was convincing hardware people that the idea of any kind of a fault is ever a good thing. And you can use virtualization in a way like we do with the in tech 5 megatexture in a completely non-virtualized way and non-blocking way where, you know, we let things go fall back automatically, update as needed. But to be able to use it for something like geometry meshes, you really would like it to go ahead and say, I don't mind blocking for the 1.2 milliseconds or whatever. It's going to take for this to come in from flash. Hardware people still tend to run screaming at this concept that you're going to idle their cores for 1.2 milliseconds. But that's again one of those things that they'll, they just need to get over it. It's a net positive win for the entire system to be able to enable some of these things. I mean, to be able to have an entire application where all of your media resources are just set as completely static memory mapped resources that you have pointers to. Yes, a smart app will go ahead and pre-touch manage the paging of all of this. But so many loading and saving issues and issues with stability issues with games come from loading and managing and caching and dealing with all of this stuff and making a whole class of stability things just vanish. That'll be wonderful. But it's still an uphill battle. And then once they, you know, once you've convinced them that, yeah, this is probably a good idea, then it falls back to, well, Microsoft won't play ball on this. I'm, you know, their, their OS core OS is very, very conservative justifiably so. And there's, there's value to that argument. But they're not, I, it's this extra level of difficulty. And Nvidia keeps telling me whenever I suggest something esoteric that I need to start using Linux as my development system because they'll go hack the current system. They'll go hack the kernel for me right there and send something over. And it's, it's been sorely tempting in many cases because that ability to just have something just hacked right in. Even if you know it's not production, but just to be able to answer a question, you know, that's really great. I've got a couple things right now that I'm looking at that I really want these questions answered. What worry about if it can be product, how it should be productized once we learn whether it's actually a good thing to do. So another GPU thing that's interesting is the, the place for tiled renders. And this is one that I may have gotten wrong many, many years ago where I was, I really disliked the power VR architecture way back in the day when you had the, you know, the voodoo cards and the things that that were sort of friendly to develop for that just blasted right to a frame buffer while the tiled renders. They theoretically traded, if they traded some complexity in the interface and the lack of sort of direct manipulation for a memory bandwidth efficiency in theory. The problem with the power VR, there was a lot of issues with not having the proper blending modes and there were driver issues and the limits of the tiling architecture had some fundamental limits at that time where if you went up beyond a certain amount, they just broke, you know, those, those are largely fixed now. And of course, imagination technologies with power VR went on to largely dominate the mobile space with the tiled renders. And they're really darn good now. They're, they're high quality drivers, they're highly performant systems. You can get excellent performance out of them with good tools to back it up. And there was a conversation I remember having at a 3D effects technical advisory board where there was one of the other guys was basically saying it's a foregone conclusion that tiling architectures will win. And he, he was macing that on the fact that render man is essentially a tiling architecture. And I'm not sure if that train of reasoning is exactly correct. We have, because memory is expanded, at least in pace with, I, you know, with the limitations of, I mean, the scope of memory has expanded even though the bandwidth hasn't. So these massive frame buffers, you don't have the same, picks our head to be tiled because of memory reasons, not because of performance reasons. And that's not necessarily true for us here. But they've done certainly a good enough job that, like I said at the beginning, it was credible that you could have imagined a next gen console by Microsoft or Sony having scads and scads of tiled renders. They, they scale really quite well in many cases. So I'm not sure where that's ending up. We do wind up with, I essentially untiled architectures for the, the current graphic system. So there's still life in them yet. And that's going to be interesting to sort of follow on. And I am taking way too long going through these. So I still think that the, the real action and the things that make a difference are in I.o. devices. What we do on the screen makes a difference, but what you can do that's not a screen can make more of a difference. Or what you can do to make it better. I, displays are remarkably good nowadays. I, I had a couple experiences just in the last, the last couple months where I was looking at something. I was in a shop. I saw something up there. And then I was startled when it moved that it was a video signage rather than, you know, rather than just something statically printed there. And one time I pulled my, my iPhone out of my pocket and it had a car room card key stuck on the top right inside the bezel. And I spent a moment staring at this going, how did this image get on my, on my home screen before I realized it's like, oh, that's a physical card placed on top of the, you know, stuck to the screen of my phone. So we are really most of the way there with display technologies when, you know, when I'm mistaking displays for reality. But there's still things that, that can get better on it. It's great to see some of the things like viewing angle is almost a dead issue. And, you know, there's improvements that could be made in pixel fill when you get up really close like if you look at things under magnifiers like an head mounted display, you can complain about gaps between pixels, but that gets addressed as resolution gets better and better. And displays are amazingly cheap. There is a picture of me that was in some magazine that showed me with two LCD screens square aspect ratio that were 1280 by 1024 many, many years ago. And I think that's a $10,000 each for those IBM displays. And I, you know, you think about for a couple hundred dollars now gets you a good 1920 by 1080p display. That's, you know, the miracle of modern electronics and that's a really, really good thing. About the only thing that's gotten that's not going well in displays is latency and there is, there's a trend to more and more things that happen between the bits going in the HDMI port and pixels lighting up on the screen. Now, there's, there's more adoption of gaming modes. In videos pushing pretty hard on the manufacturers that chip level to make sure that a gaming mode does the right thing that it, you know, it feeds through directly and doesn't add latency. It's, it's a little bit tricky when you think about things like if you're feeding a 1080p signal into a 1080p display then it's obvious what happens. But if you're feeding in a 720p signal then it's got to be refiltered at some level. And I mean, that's another thing that gets done wrong all the time. I, you know, they're not gamma correct usually in the resampling. They, they may do various other filters in it. But what we need is a bit going over the data stream. And this comes into the whole, oh, God, how do we corral all of these people? So we need something at the driver level. We need something at the hardware level. Then we need something on the TV that listens to this and actually does something different. But that's what we need is anything that's generating an interactive signal, something where you're doing something and it's generating an image of the device. It's generating an image based on what you're doing should be in no latency mode, no processing. Because a lot of the processing that gets done is sort of assumes an imped compressed stream and games are, you know, are not that. And we, you know, that should be turned off because in some cases it's generating a polling amounts of extra latency. So that's one of the things that has sort of regressed a little bit. And that happens in a lot of areas actually where you get bandwidth increases at the expense of latency. And sometimes clock speeds go up enough that the latency decreases in an absolute sense anyways. But we've hit limits on clock speeds in a lot of cases. So now as we're increasing bandwidth, we're getting more latency. And there's a lot of just sloppy programming not knowing that it's important in all the different cases. But that's something that I push hard on and I'm hoping that, you know, there will be continued improvements in that. Resolution, you know, where we look at phone resolutions when you're at retina display and retina display as its term now doesn't mean more resolution isn't, isn't beneficial. You can still see ali seeing if you look at a wireframe rendering going on a phone at a normal display distance. But it's, you know, it's pretty damn good. I would be as an image processing or as an image rendering producer, I wouldn't be too sad staying at a 1080p resolution and concentrating on getting the anti ali seeing right and all that. It would be, it's nice right now and it might be a brief window where 1080p usually does mean 1080p pixels. The 720p was not like that on hardly any displays. They were always resampling and that was a bad thing. So I worry that more resolution, if you start getting displays that have two and a half k resolution, then those are going to be resampling all the input signals we're going to go through all of these same problems again. There's going to be more latency added, more non-gamma correct up sampling, all sorts of problems. But it does look like that the industry push for 4k is, you know, is gaining momentum and it seems almost ridiculous to me that, but it's going to happen. The electronics people need something new to sell, so they're going to make 4k happen. It's not clear to me that that's going to make a huge win on people's walls and displays. The selfish thing that it is going to be great is it's going to be good for the place where we really desperately need resolution is the head mounted displays. You know, when you're looking at your PC or your TV screen, resolution is pretty good. Maybe it's not everything that you'd want, but in head mounted displays we really do want a lot more resolution. And we're going to get it, you know, not because the display manufacturers particularly care about that market, but because they need to have bigger, bigger, bigger numbers on it. The megapixels race on it, and we're going to have, you know, it seems ludicrous, but we're going to have 4k tablets and mini tablets in not too many years. And that'll make a just a dandy head mounted display for that. So there's going to be some value coming out of it, but I think that is kind of going beyond the knee of the curve and benefits to consumers again. Refresh rate is something that has a, there is room, there's room for improvement there. A lot of displays now do 120 Hertz internally for 3D shutter glasses, but very few of the consumer devices take it as an input. And even a lot of PC monitors, you have to hook it up with just the right cable and enable it just the right way. But 120 Hertz displays noticeably nicer. It's not going to change the way you look at things or make your jaw hang open in astonishment, but it's nicer and smoother and it affects everything. Everything on your desktop is better with, you know, at 120 Hertz. So there's room for hoping that that goes, and in our limited bandwidth budget, I'm afraid that it's going to come down to more resolution, where doubling the resolution versus doubling the frame rate. At this point I would take doubling the frame rate. You know, at different points there would be different trade-offs between that, but I just hope that whatever bandwidth we get we can choose to deploy as a frame rate in addition to resolution. The actual stereoscopic for shutter glass TV is still, you know, it's not a world beating feature. When you set it up with all the right parameters, if you have your stereoscopic screen set up with the parameters set so that it is an extension, your field of view at the distance you're sitting for that size of screen, the field of views correct, the projection matrix is correct, and the separation for your eyes is correct. It can be a really powerful experience. You can have that sense of I can put my hand through the screen and grab that thing there. But there's a lot of reasons why you almost never actually see those set of parameters. In fact, one of the console vendors has a limit on the maximum screen separation, which is somewhat below what you would like to put on it. The reason it's like that is because it causes eye strain as you deal with your eyes wanting to, they know how much they have to tow into, to center on something, but they're focusing at a different amount. This is the virgins effect, and that is an issue with eye strain and we generally try to minimize it by tuning it down a little bit. But you also have lots of issues with the game content that we're putting in where if you have your monitor a certain distance from you, that would mean that in-game, if you were doing it all exactly, right, you would not be able to show on screen something that's going to be closer than that, where in first person shooters you've got the whole issue of your weapon, which is positioned in this aesthetically pleasing orientation and field of view for two-dimensional rendering, but it's just wrong for 3D, and it's not completely clear what we want to do on there, where your your, ideally you would have something that if you've got your screen out there, you want something which would only be like holding it sort of, you know, at a distance that's not realistic, because if you hold it at normally you can project it onto the screen, but then you've got something falling off at the edge of the monitor, and that's another eye strain inducing thing that causes problems. So, you know, stereoscopic stuff is not too hard to do. I think it's an excellent stepping stone towards the head-mounted displays and virtual reality, which I do think is one of those can make your jaw hang open and really make a difference effects on there. So you can pick it up sort of along the way as a destination on its own, it's still not, you know, not super awesome. Now, the one exciting thing for me that happened just in recent months is I had to reevaluate some fundamental assumptions that I had on what's important on the displays. And this is great for me because this is something that I, you know, I've never talked about it. I haven't talked about in the previous I talking about displays, but the issue of persistence and jutter, where Michael A. Brash's team at Valve has been pushing hard on this, and the first time I went and talked with them about it, I was really skeptical where I might know I want 120 Hertz display that will fix the problems that we have with 120 Hertz OLEDs problem solved. That was my position. But they went in, they've built some test hardware, and the best way to win an argument is to, you know, build hardware and prove it. And within, and it's great the way they did this. They basically knew they wanted OLED displays, so they pulled apart Samsung Galaxy 4 phones, and they had their hard to do. And they had their hardware hacker guy right in, make an interface board that lets them drive a pair of Samsung phones directly from a PC on. And then they added this extra circuit to be able to change the persistence globally on it. You can tap a button while you're going through changing that. And I put on their prototype, and 20 seconds later, you're right. This is absolutely important. I retracted these statements that I made about the lack of importance of persistence. It's a compelling thing. But it makes some, so, and there's a couple of really interesting things about this. CRTs back in the old day had essentially no persistence. I mean, really old CRTs would have long persistence phosphors, but the CRTs that we would use for monitors and gaming had extremely low persistence. The electron beam swept over, and the bright spot was gone in microseconds. Now, when I look around online, there is a class of people that have been really bugged by the transition to LCDs for things like, apparently, watching sporting events, which is something that I never really do. But the people that really pay attention to watching their Super Bowl game, that a lot of people thought the experience once we moved to flat panels has just been worse than it was on a CRT. And I never understood really what they were talking about until I was able to look at it more from inside out on the head-mounted display perspective. And there's a good example. The problem is, if you're looking at something with a CRT or most displays now, they're on all the time. It's fully persistent. That was great because there was none of the 60 Hertz flickering, eyestrain issues that displays our solid. They look like the reality signs. It was good for all of these things. But when you have something move, it brings up the fact that instead of like moving smoothly, it's all here and then it's all here. Or worse, when you're tracking something in a head-mounted display, this pixel that's here and it's going to change to something else, the same pixel gets dragged as you're moving your head. So it smears across this area. And what I originally chalked up to motion blur being crummy LCD switching times when I would see, like if you put on a rift and you move around, you've got these, everything, it can be fine when you're looking at, but when you move everything smears and then comes back stable. Now, it certainly is a problem. There's a 20-something millisecond switch on the LCD. But even when you do that with an OLED that switches in a microsecond, you look around and you can't read something as it's moving. And you can do a test of this with any sort of smartphone device. If you've got text on something, you move it up and down. You can totally focus on a line and read it as it's going. But if you're scrolling it, even at a liquid smooth 60 frames per second, scroll fast and try to read there and you can't do it the same way because you've got this persistence jutter that blurs the text going. So, it's an important deal. Now, it's questionable how much of a difference it makes for a conventional gaming experience. I did dig back up an old multi-sync monitor that I could run at 120 Hertz low persistence, which would be, you'd think better than what this demo was. And it still doesn't make that much of a difference to me on standard gameplay. Now, I couldn't sync the demos that I wanted to on there because it was an old square aspect ratio. It wouldn't take the other stuff. So, I couldn't make a completely fair comparison. And I think that's still a worthwhile thing to do is go back and dig out the 10-year-old monitor and put your modern best of breed graphics engine technology experience and see if you can make it look better if you can run something at 120 Hertz. So, it's not as that better than looking at the 60 Hertz low persistence, looking at an existing display. And I don't know. But for a head-mounted display, it's a world of difference. But one of the fascinating things that comes out of this is one of the other technical directions that might be happening with fully persistent displays that's frustrating that it hasn't is non-isochronous updates where right now we update 60 times a second clockwork. And that's why we have vertical tearing or I sync tearing when you swap and you swap in the middle. In a lot of cases for a lot of displays, what you'd love to do is just say, well, I'll tell you when I'm done, here's the entire frame. That would mean all of the hot-routed PCs. It's better to go 62 frames per second than 58. It actually makes a difference or even 37 versus 35. Any amount that you go better would be an improvement in smoothness. There would be a positive thing to that and I thought that could be in-run-in by mobile devices that care so much about power consumption. So, that's I, and that was in the DVI spec again, 10 years ago, but it hasn't really come about. It probably will in coming years for mobile stuff. But that's directly in opposition to this low persistence display issues because for low persistence display, you're just flashing an image on a regular basis. So, you need an isochronous display. It needs to be happening at a particularly relevant regular time period. So, there are two directions that both add benefit but are absolutely contradictory to each other, which is going to be interesting to see how that plays out. I hope for this, the other thing with that with the low persistence is that 60 hertz is not good enough. 60 hertz was really not good enough even looking at your monitor. On a TV set when it's a long ways away and it's sort of in your foveal region. It's okay, but it always flickers when it gets out to the outside of your view. I put this in a head-mounted display and most of it's covering your entire field of view. It's completely and utterly unacceptable. I thought that 120 hertz is certainly good enough. Valve's running their stuff at like 95 hertz, which brings up the question that I was lamenting earlier about how why can't we have game developers even make 60 hertz games when there's still people looking for 30 hertz saying, well, now we got to do 90 or 120 hertz. That's going to be a challenge. That's not happening in the real near future. But one of the most exciting technical research things that I did in the last year was this notion of time warping where you take an image at a particular orientation and rendering and then you warp it to be rendered for a different position or orientation or time. That I'm hoping is going to be the solution for this where we finally have a hard real-time situation where 90 or 120 times a second we absolutely have to deliver a new image, no ifs ands or buts. But perhaps that image is coming from a source that's only updated maybe even only at 30 hertz. So that should allow completely smooth like mouse look or head look on there for transferring the rotation or even slight movements. But it won't handle anything else in the world. So you've got if you have your drifting snowflakes in the air probably won't care if they get a frame here or there in a slight stutter. But if you've got some performance art thing happening in front of you, that may matter. So what might happen is you could imagine taking the reviled motion interpolation technology from consumer television and coupling it with the time warp presentation technology. So your world is always 30 hertz with one frame of extra latency there. But you use motion interpolation at an image level, maybe augmented by marking or depth buffers or things that we could do since we know we create this stuff there rather than interpolating it from an impact stream. But you use that to generate 120 frames in between and then you time warp the presentation so that you have no latency for the actual viewer. So that's something that might actually pan out. So I'm very excited at some of the research opportunities sort of in the next year looking at that where we might be able to kind of get the best of both worlds have our cake and eat it too. On the input side of things, we've got I, yeah, I've got, you know, I'm only halfway through my list here. So the, you know, talk about how touch is so amazingly natural. It is the most natural computer interface we've ever had. And watching kids interact with this is really remarkable. And to think that we had touch screens, we have light pens and things like that for so many years. And it was only until the smartphone and eventually a tablet that this made its really made its mark. And it's interesting to wonder how many technologies could be like that where they're nichey things right now. But five years from now they're going to be ubiquitous and kind of the cornerstone of the way we interact with things. And you know, mouse and keyboard have, you know, are certainly the most precise current thing to be interacting with. You've got the direct relative motion. It's not direct interaction because you're moving your hand and interacting with something there. But it's still highly precise. Game controllers are still unfortunately really, really a bad interface for certain types of things because they're not direct interaction. And in the old days, like a game pad for a Nintendo, you know, a super Nintendo or Nintendo game pad was actually not an unoptimal interface because all you did was Mario go right, Mario go left. It's a binary interface. The button was completely reasonable for this. It's only when we started to do turning on game controllers and bringing analog into it that it became a really, really bad thing. Or I mean, it's better than binary having an analog on it, but it's not good. You're using this course low precision muscle in your thumb and time integrating. And you watch people a lot of times playing games and they're even pulse with modulating with their thumb, you know, rather than trying to get the exact analog position and wait the right amount of time. You know, it's like snap snap snap trying to kind of bump your way to the right position. And it's just not good, but it's what we've got to live with there. So, you know, some of the controllers where you start to see sparks of bitterness, I think the PS move, it's still got kind of a latent kind of laggy interface to it, but at least you're moving something and you've got buttons. I think the the razor hydro with the two tracked things. It's unfortunate that it's got wires and doesn't have it any feedback inside it, but I think something like that will be where we wind up where you've got sort of the split thing. You've got two hands that can be moved and tracked independently while still having all the buttons to kind of do your intentional actions on it. So, I think there's things will migrate that way, usefully. And then some of the other things like the the PS3 gun controller where you've got a tracked gun with a we move and a thumbstick on the end of it. Things like that will be really, you know, work. That's a good interface for things. If you had that in sort of virtual reality environment, that'd be exactly what you wanted there. And when you're interacting onto the screen, it's got that layer of separation. So, it's not perfect. You know, the tracking is still a hard problem. And it's it's still remarkable to me that something that seems so fundamental about where is this? Where am I? Isn't just some male down solved problem, but it's not. There's still a ton of research going on. Again, Valve has done some really spectacular work with optical tracking where you've got things like the track I are that looks at the little dot. And has works pretty well in here and then falls apart when you get out of the field of view. You have the RF tracking things like the sixth sense that work more or less everywhere, but are not very accurate and have different fall off characteristics. And you know, there's inside out. I think that my take is that eventually head mounted displays will wind up tracking with inside out tracking where you'll have cameras on them looking out at the world because that's how, you know, that's how the brain tracks and we should be able to mimic that. But it's there's a lot of challenges, especially for absolute positioning. I suspect that there's a middle ground between absolute six degree of freedom, ground truth, here are the coordinates that there's a useful intermediate step between just accelerometers and gyros where you have relative positioning to it. And I think that there's potentially benefit for using optical flow analysis coupled with the gyros and accelerometer accelerometers that are on there to get useful relative motion. This is all stuff that hopefully can be experimented with and worked on sort of in the coming year. I have not yet tried one of the funny standing platforms where you know you get to stand on the treadmill rotational stuff. I've talked to some people now that have used it and nobody has said glowing things about them, but maybe they maybe they will yet become something interesting. Most excited for that type of stuff for taking the sort of indoor laser tag areas and turning those into virtual reality play spaces, which has the advantage of you are completely free to put marker graphics on every wall floor and ceiling. So inside out looking would never be outside would never not have a marker. I think that's going to be just fabulous when that happens. You know the audio side of things is the audio people always feel like the poor stepchildren on the development team where they get the scraps of the resources I given over to them. And we've at least twice before tried sophisticated audio processing and we just kept coming back to it doesn't win yet in game when you don't know what the speakers are when you've got the broad range of things there and you've got a screen sitting in front of people. I mean maybe it's been the wrong call but we've looked at it a couple times and it still hasn't really won but in a head mounted display I think it's going to be amazing. I think that having head tracking on it to be able to do that full head related transfer functions so that you can close your eyes and echo locate inside the rooms essentially. I think it's going to make an impact there so I think there's going to finally be some happy audio people that will feel the center of the universe much more than they have in years past. I'm on the software side of things now the one of the things that I think I feel I've probably learned a lot more in the last three or four years about large scale software development than anything else there's been the work that it was an amazing learning experience to go through and take our entire multi million line code base and get it squeaky clean with code analysis. And that was an experience that I wish I could just sort of download into everybody because I still run into a lot of people that when you talk about things that are unsafe practices or things that will cause problems that's such a mushy nebulous term it's not like I can count the cycles and show you why my way is better than your way. And I don't know how to like win arguments about things like that but there is wisdom to be gained for looking at those experiences but you know getting adoption across everything is still you know is still very challenging. And one of the biggest things that we've got in our code base right now is the inertia of the optimization that we had to do for the previous generation. You know there are a lot of scars involved in getting the 60 hertz gameplay experience that we had for rage. And a lot of the things that we did there just don't make so much sense now and extricating them unfortunately isn't as easy as just saying well we're going to chop this out here and here because there may be something in the model imported that goes into the layout code that goes into the manifold generation code that funny comes into the produced baked model loading code and they were all necessary to get what we you know what we wanted to achieve and what we did achieve previously. But there are there things that hold us back now that we need to get out of we need to de optimize much of the code to make it I to make it much more. Less special case because it's the things that bite you over and over that have assumptions that are in multiple places in the system but that's where all the really good high payoff systems optimizations are where you can recognize that. Oh if I do this over here and this over here and this here I get this synergistic win that you wouldn't have gotten from any one place. But those are also the things that are then harder to dig out of the code base later on and we have a lot of that in our you know our asset pipeline the the way models are imported and things that we've tried to do for convenience tried to do to make things nicer for people. That's one of the big lessons is except lenient was is just a bad idea and the web world learned this I you know to the you know to billions of dollars of effort expended on that across browser compatibility from except lenient where you really want to be hard ass about the assets that you take in especially when you control them you want to say it's either right or it's not right. And if it's not right I just don't allow it don't fix it up and let it go with a warning because nobody will look at the mornings and that's something that we're still kind of working our way through where I we need to get to the place that in the code we are squeaky clean on all this static analysis we need to get that way with all of our data assets we need to be able to say all right all of this data it comes in we apply link for models to it and get it get it squeaky clean and it's going to be good it won't cause these other problems where right now we you know it's it's sad how much time we spend chasing problems where something comes in it's messed up in some way trying to infer what level of this munging process pipeline. I you know made it that way so simplifying things in that ways is one of the big sort of strategic things that we're working on. But in general this push for robustness first then predictability then performance and we've been I am you know our code robustness has been really great with our stable code branch I think that we've had really high quality software. All of the import pipeline I worked on I did that I sort of triaged that when I was doing it because this was millions of lines of code I concentrated on okay here's the stuff that runs when we ship to millions of people this is the code that's going to be. run millions of times millions of different platform systems. I did not pay as much attention to the loading code the tools code and so we have more problems with that we also have the age problem of our tool base still has some of the very first code that I wrote on windows you know all the way back to my first in T workstation was the first editor that I wrote and there are bits of that there's still fixed function open GL you know immediate mode fix function anymore probably but at least immediate mode of the at least immediate mode open GL code in there that I know that just sets things and that is far and away the least stable part of our code base but you get into the question of well you know you don't just stop the world and rewrite everything we've done a few big initiatives with a couple a couple large scale changes inside there but the framework that it's working inside is still this creaky old thing. actually that one of the things that I spent a lot of time the first six months of this year on was actually user interface code related to user modibility and I probably I can't talk about it publicly now but one of the big features that we've got going forward was something that. you know I went back and wrote you I code for the first time in many many years where that was you I code was always the first thing I pushed off on to the junior programmer where. all right it's like you do the menu code in the you I code now I work on this fun stuff I. and I would seems like I revisit that now every five years like I did I did the you I code for the IOS. and I was in the IOS. I'm you know Wolfenstein classic and Doom classic originally and that was interesting to explore some new things and it was interesting to kind of come back now that I've been. internalize the whole functional programming paradigm and ways to do things there so it's I. we're building up new chunks there but we still have the sort of dangerous no man's land of very old code that's been patched by 30 different people and is is problematic. you know API wise like you know we do still have some of the old OpenGL immediate mode code in there it's it's gratifying to look around and see that in the larger scheme of things across the world. OpenGL sort of one which is I. you know which really wasn't expected even even five years ago where we were kind of thinking that okay it's you know it's not evolving fast enough Microsoft doing a spectacular job with what they're evolving with D 3D. and something huge said the one that was alash good luck but it started in Hobont Republican and because it got ready for the long you got a lot in doing the use. and some of the other things treating it like a CPU, but it's still a good thing. And I can give myself a little bit of a paddle on the back for all the work that I did to kind of help make that happen over the years. And I think that the industry as a whole is definitely better off for that. And it's not bad to have Microsoft doing a great job with all the D3D stuff, but it's good to have a couple competing paradigms and something that was, that wound up being free for the platforms that are going in thousands and thousands of different things. So that's been a good thing. On the rendering side of things, physically correct lighting, it's wonderful to see that that's all the rage now. It's all anybody's talking about for the next gen stuff. And it's good. It will win. It will be better. We've seen this story before with the offline rendering crowd about being resistant at first and finding out that it actually does make their lives easier. I made a push for this several years ago and did not get enough internal traction with the art team to kind of buy into it. Because it requires changing things, looking at a different way, giving up your favorite tweaks and hacks and the ways that you know how to sort of beat the current rendering equation into submission. But we've had, we're in a situation where we've got a lot more buy in now. It's got public mind share. It's going to be the way things are going. We'll always be approximating it to some degree, but trying to have somewhat plausibly rational albedos and having things that make a little bit of sense is just a good thing. And then the end, it'll be easier to make content that works well. So my big software evolution over the last certainly three years and stretching back tendrils a little bit further than that has been this move towards functional programming style and pure functions. And it's been long enough now that I can really take some valid data points from it, where I can look at some code. I just ran across this last week. I was looking through some code and I came across this file full of a bunch of reasonably sophisticated code that turned out we're not really using anymore. But it is just that they're completely innocuous, not bothering anybody. And it had been written in this functional style where it was all self contained. And I count that as a win. And there's a number of things like that where you look at this and say, OK, this is a lot of complex, sophisticated code, but it's a pure function. It's just completely compartmentalized over here. You pass in stuff, you get out stuff, and anybody that's not calling that function does not care whether that code exists or not. And that could be contrasted with so much other code that has assumptions and interactions and tendrils throughout the system where there are so many things that you set a flag here or you call this subsystem to put it into this state so that something else that you're going to do later will interact with that in a different way. And we have the horror show of that right now is our build game code, the stuff that goes and you say build game for these maps. It sets all of these hooks and flags throughout our resource loading and file system to be able to get callbacks on these different things and then runs and starts up the map and there's different flags and console variables. And it's just got awful and it causes us problems on our maps weekly basis. And I've got enough of these positive cases to stack up against this to say it's usually more of a pain to try and write something in this self-contained functional way. But if you're going to use the code for years, it has large advantages. I'm seeing the payoffs more and more as I just on a regular basis, I see these wins where that's been happy and good because it was written in a pure form. That's been a real pain because it wasn't because it used callbacks and tendrils and flags and settings and all these other ways of doing things. So I am more convinced than ever that it really is a big win. So I've been applying this for years just the notion of functional purity in C++ in my day to day writing language. And I've gone and poked around at the looked at Haskell in different places. But I never wrote a significant amount of code. In the last year I set out to go ahead and try and get sort of my 10,000 lines of code in real functional languages to try and get something that I can talk about their merits in a concrete sense rather than an abstract sense. And I had been, it was one of these things where I programmed just enough that I always had to go review the tutorials each time I did it. I'd go through the beginning Haskell tutorials maybe three times where I'd learn this, I'd write some code, come back six months later, forget all the ways to set up the imports, go through it again. But finally trying to write enough code to make it stick. And the project that I set out to do on this was I wanted to do something that would be enough code to learn about the large systems because when you look through exercises in books, they're toys and there are completely different set of things that you learn when you're looking at system scale versus exercise or toy scale. So it needed to be something with a little bit of meat on it and something that I could reference against other things that I've done. So what I set out to do was take the original Wolfenstein 3D and re-implement it in Haskell. So I started off with loading the assets into there which are in this god awful old format. Back when I was fitting things on floppy disks and I was reinventing compression methods for myself. So it's some RLE on top of very badly bastardized, independently invented LZSS thing. That's just this messy binary format, which you think, okay, maybe this isn't the greatest thing for implementing functional purity, but it turned out that that winds up being a lovely little bit of functional code to do that and it's a fraction of the size of the C code. Where you hear Haskellers and people talk about a tenth the size of equivalent code and that's probably an exaggeration. But I believe that some of this nicely commented clean Haskell code can be a factor of a few smaller than the C plus code that I was porting to. I got to the point of having the guards on paths and walking around, running player movement at some basic levels. But I was finding that it's really difficult for me to work on something that's not work. I have this, I would pat myself on the back for tearing away and spending a whole hour on my Haskell research project every now and then and I couldn't hit it on a regular basis. It was just not, I didn't have enough time to, I couldn't make myself take the time. I mean, I just have that internal itch that's like, oh, I could be doing something that's productive in the here and now. And I know that it's good in the long term, but it's a little, you know, it's a character issue that makes it difficult for me on that. So one of the things that happened then that was sort of a happy I good fortune is I had, you know, I'd always been poking around in one of the languages that I would look at. I settled on Haskell as probably my, my functional language of choice to follow up on. And I generally still agree that that's one of the strongest directions. I'm still not completely sold on the value of laziness so the people that talk about ML derivatives, they might have a point I haven't evaluated side by side. So there may be something there. But one of the ones that I at least considered and rejected was Lisp and Lisp has, you know, there's a lot of history to Lisp. It's just about the second oldest, well in use language, it goes back to the 50s. And I've always had in my head Lisp almost up on a pedestal. There are things like, I'm, you know, a formative book in my teenage years was hackers, here's the computer revolution. And a lot of that talked about the MIT computer crowd and you had the, you know, the building of the Lisp machines and the Lisp hackers and Richard Stallman's last days there. And that, you know, that stuck with me a lot. And there's things reading Paul Graham's essays, reading the Unix haters, handbook and the people that, you know, that would still talk about these, these old Lisp machines and the values of it. Oh, and my favorite paper title now is there was a paper by the, the people that became the, the racket scheme system. And the subtitle on it is revenge of the son of the Lisp machine because about programming language environments. I thought that was just a fabulous for a paper subtitle. So I'd always had this sort of Lisp up on a, a bit of a pedestal. And I thought, well, it'd be great to have deep Lisp knowledge. Because I've heard plenty of people say, oh, just learning the syntax, that's not going to do anything for you need to, to write enough code to sort of get the, the zen of Lisp. And for years, you know, for decades now, I thought, well, that'd be nice. But, you know, I'd pay money if I could get the brain download to do that. But I just can't see myself ever having the time to do that as witness by my trying to spend time on Haskell. I just, I can't make myself spend that many. If I'm sitting at my workstation, I want to work on something that, you know, it's relevant to the current project. But I, what happened is I found out that just poking around, I forget exactly how it came to my attention. But there's a tiny little Lisp development environment that you can get on the iPad called Lisping. And it's, it's this sort of visual editor matches up all your parentheses and you couldn't write a real program in it. But you can write scheme in it. And, and go through and do exercises and it shows you the, the arrangements. And it's kind of neat. You know, I look at that as, okay, this is the idea of visual programming is never really taken off. And we all still wonder whether at some point we can extract more of the structure of the programs beyond just syntax coloring. And we can do useful things there. And Lisp with its nature of everything's an expression and the homogenous city of it has a lot going for it. And still, this is a trivial program. But what I found out that was just magical to me is that I had my iPad with me at like all of these times when I'm not at my workstation. And I found there were all of these little hours where I could be doing programming if it was on my iPad because I'm at home sitting in a, you know, on the couch somewhere. I'm on an airplane or I'm stuck someplace. And I don't have my system. So I don't have that same personal guilt trip about not working on the work that, you know, that I need to move towards the next milestone. And I could actually do, you know, some real programming. So I, I, I picked up and I spent a decent amount of time learning scheme. I'm doing some work on the iPad writing a few simple programs, write a KD tree, I am builder, write a parser for something. And eventually I did wind up with one of the, the grand old books of computer science, you know, structure and interpret interpretation of computer programs or sick P there. And that's, you know, it's classic MIT text. It's for undergraduates. It's supposed to be sort of a first MIT course. But it uses scheme as the programming language. And it's one of those books up on a pedestal that are on the books every computer programmer should read. And, you know, I started going through, I took, I actually took some time off from work and said, I'm going to do Lisp immersion. I'm going to spend this week doing nothing but Lisp programming. I'm not even going to think about working on what I should be working on. And that worked. I was able to go in and clock a whole bunch of hours and, you know, get to the point where I pretty much do get it. And I get some of the, the value from it. And the, so this undergraduate book you think, okay, why, why is John Carmack reading an undergraduate textbook on computer programming? But there's still, there's value to be gotten in, you can find value in almost anything at that level. Any college textbook you pick up, you can probably get good value out of it. Even if it's a topic that you already know. One of the things that's, that I, I crossed some threshold in recent years where I've always loved sort of reading, grazing on technical stuff. I've always liked textbooks, reading them. I, you know, like bedtime reading for whatever. But in recent years, I've gotten to the point where I actually look forward doing the exercises. And part of that's because getting older, you know, things you need a little bit of an extra push to make things stick in your brain. And I was talking with my, my stepfather was an engineer. I about that. I mentioned that. He looks at me and says, he's set, he's pushing 70. He's like, you have no idea, John. So I'm not sure I'm looking forward to the, you know, the slow decline towards that. But the, you know, working the exercises in the book is, you know, is obviously useful. And the thing about, I, you know, this particular book, where if you take your, you know, learn language, XXX and 24 hours, you just get these very practical, little exercises. But here I'm going, looking up, traveling through Wikipedia and going, okay, what's an Ackerman function? What are these church numerals and all of this math basis stuff that was kind of entertaining to learn why I'm learning the programming challenges along with it. So I do think that I sort of get Lisp now. And I have, you know, working ability in Haskell. And I've got a few conclusions coming from it. One of them is that there's still the question about static versus dynamic. And I know there was a survey just coming out recently where the majority of programmers are still really not behind static typing. And I know there's the two orthogonal axes about whether types are stronger weak and whether it's static or dynamic. And I come down really pretty firmly and all of my experience continues to push me in towards this way that strong static typing has really significant benefits. Sometimes it's not comfortable. Sometimes you have to build up a type scaffolding to do something that should be really easy. But there are real strong wins to it. I see this in the code that causes us problems in my toy stuff in recent months seeing the, in the Haskell stuff that I was doing, the one head scratcher where I was looking at something going, what the heck is this doing? Why? And I desperately wanted a real debugger. And Haskell does not have what I would consider a real debugger. The one thing that was there turned out to be the part of the data that was untyped when I was still looking at these two planes of data for the Wolfenstein data. And I just had them backwards and it was causing bizarre stuff there. That was the only thing that really had me baffled for a little while was a case where proper typing would have removed that if it was the only typing throughout it. And conversely, in the list work, I had a bunch of cases where I was doing something that was just wrong because the types weren't there that was statically typed, it would have caught it ahead of time. Now I do see more of the charm now that I've had some experience with a dynamic language. I see the lure, the enticement of having just throw random types onto anything about not having to have sort of template typing arrangements and things. You're, there's an appeal to that. But I think that it bites you in the end if the code lives a long time and it grows enough. I think that the value of types is just super, super important. And that's something that's going to, it's a religious argument among programmers. And I despair a little bit about trying to win the arguments in a, you know, in a convincing empirical sense because these do come down to these tendencies of programmers. And if somebody's being, I, you've belligerent about it, they can just say, well, I don't have those tendencies. And I can say as, you know, being a lead programmer over, I, or a technical director over dozens and dozens of programmers, millions of lines of code, it's just amazing how, you know, how many mistakes and how bad programmers can be. You know, everything that is syntactically legal that the compiler will accept will eventually wind up in your code base. And that's why I, I think that static typing is so valuable because it cuts down on what can kind of make it pass those hurdles there. So I, I'm only getting stronger in my, you know, my stance on the utility of static typing, static analysis. I, you know, don't let those things just kind of happen and get fixed up at runtime. So one of my, I, my sort of sneaky plan for turning the, the Haskell work on Wolfenstein into something that was going to tie into real work relates to a vision that I have for using, uh, multi core and game logic in a different way than we're doing right now. So the state of where we're at right now with game code is that we run all the game code in one thread because the idea of using locks to synchronize amongst all of our current game code was just absolutely terrifying. Uh, the heavy weight lifting stuff that we do with collision detection, pathfinding, I, a lot of the, uh, the, the stuff that would take up tons of work, building extra particles, uh, animating skeletons, all that gets run off into jobs that are done with deferred, uh, calculations. It's, it's a pain to do things that way. You set it up, uh, but it's understandable where a developer can just look at this and say, okay, I want to do this next frame. I'll set up my query. Please go trace these 50 things and I'll deal with it next frame. I mean, it adds all these extra flags and bookkeeping, but it's, it's still a heck of a lot better than saying, oh, we're going to merrily run in parallel. I'm in a critical section, some things that way it leads to disaster. There's just no way that was going to work out. But one of the things that I've been thinking might be possible is that the thing that I wanted to test on the Wolfenstein, and I didn't really get far enough on this to, to save for sure yet. I hope to follow up and continue it. And it's arguable Wolfenstein's not enough to prove this one way or the other. But if you are running all of your, all of your actors or entities in the world independently parallel, but it's functionally pure. They're passed in a reference to a static copy of the world and themselves. They return their new version at the end. They can't break anybody else because they just, they're, they can't touch anything else. It's not allowed by the compiler. And that is, by the way, one of the things that I, I feel pretty strongly about why, why I went Haskell, rather than something, some of the other, perhaps more approachable languages, it's the brutal purity of it. You know, languages talk about being multi paradigm as if it's a good thing. But multi paradigm means you can always do the bad thing if you feel you really need to. And programmers are extremely bad at doing sort of the time scale integration of the cost of doing something that they know is negative. I mean, everyone will know it's like, oh, this global flag, this is not a good thing. This is a bad thing. But it's only a little bad thing. And they don't think about how, you know, the next five years, how many times that little bad thing is going to, to affect things. So brutal purity, you have no choice. You know, you, you do not have an escape hatch. You cannot do set bang and change something just because you feel this is, you know, this is a really good thing and it's appropriate here. You just have no choice, absolute purity. And so, yeah, the way I had that all segmented is the little bit of monadic code that happens in the main thread is just one file. Everything else is absolutely pure functions, no, you know, not even any of the, you know, the fancy things that can help you escape in some ways. But so I was proving out this idea that, okay, entities running separately, you've got the obvious question, well, how do you shoot somebody if you can't affect them? I, you know, you, you say, well, I'm firing my gun. I, I hit him. The world says I do. I want to make him die. So you have to, you have to make an event of some kind that gets communicated to, to the other entity. And now all game engines have some kind of event passing mechanisms. And in general, I don't encourage people using them because it decouples the flow of control. You can do something, if you can do something right here, it's better to do it right here, rather than have it done by some system elsewhere. But if you're in a pure functional mode, that's the only way you can wind up doing effects. And it turns out to actually be not that bad. One of the things that was one of those, wow, this is really clean in Haskell is in Tech 5 and Tech 4 for that matter. We have an event system where you can bundle up objects with different numbers of parameters and you've got issues with the typing and the number of parameters. And this is whole system for, for passing around these bundled events. In Haskell, it's a partially evaluated function that just takes an entity as its parameter returns another entity. There's no system for it. It's just built in for the language. You can have a, you know, a do damage function. You partially evaluate it with your five points of damage that you're going to do. And then you pass it so that it's just going to take that, the last function parameter as the entity. And you set that up on your own personal list. So every entity makes a list of all the things that they're going to do to anybody. And then at the beginning of the next frame, you go and you gather everything together, you find all of it. You distribute all of that to the entities. The first thing they do, they've got the world, they've got the list of all the events that affect them from anybody else. They apply all of those one after another, generating a new copy of themselves as they go. Then they do their thinking and their processing and generate the final version that goes back into the world. So there are, with this sort of method, there are coherence. Nothing gets out of, because everything sort of happens at the same time. There's no sense of time ordering. But you do have the question of it, since everybody's looking at the previous frames rendering, two people approach a narrow hallway. They both say they want to go into that hallway. They both think it's clear. So they both go into it. And then, well, what do you do next frame? They both say, well, I'm here, but two people wound up at the same place. So there's a little bit of resolving that has to be done there. And it may just, and I haven't worked all of this out, but I completely satisfied that it's possible that you wind up getting some precedence on there, use physical repulsion rather than absolute surface collisions on there. It can all be worked out. So this was my approach in Haskell. This was what I was building there. And it seemed to be working out well. It may yet fall apart on something harder, but I had to pick a research project that I could conceivably do, even if I haven't managed to finish it yet. If I had picked Doom Free, there's just no way I would have personally been able to go through and do this. But my sneaky plan to justify all of this is actually being a really good idea was that, while in C++, the idea of using everybody running the way the code is right now would not work. It would be awfully crashing and would have race conditions and it would just be terrible. But if you would code sort of in this style of you do your object from beginning to end, you could look at everybody else, but you can't touch anybody else. And you could do everything theoretically. All the stuff that we defer right now, the traces against the world, the animating your pose, the building your particles that tie on all that, stuff that as long as it didn't take more than one entire frame, 16 milliseconds, you could have straight line, pleasant, beautiful linear code that would be clear and simple and easy to step through, tell what's going on, not this mess of deferred and handed off to different subsystems, queried the later frames. You could make code that would be nice again. It would be code that looks like Quake 1 through 3, where you can just say, you start here, you go through, you do all of this and you're done. That would be a really powerful thing for game development. If we could make game development twice as easy on the game programming side, we'd have twice the iteration time, get games done in half the time. It would be a huge, huge win to make some, doesn't have to be an order of magnitude, but a factor of two would be monumental. So what my thought was is that, okay, we can't have things that just randomly look around at all this, even if you say you're programming in this look only way, but if your pointer is let you point at somebody again, if it's syntactically legal, it will make it in the code base, it would be almost impossible to guard against. My scheme was, instead of taking just your single heap here, go ahead and pretend you're doing guard, actually do garbage collection, which another is another thing that garbage collection is a benefit for developers. It has a bad name, a bad reputation in game development for intermittent pauses. Intermittency is bad, a fixed overhead we can deal with, and it makes programming easier. And programming is often the long poll in the tent for getting games done. So anything we can do to make this easier to spend our performance is going to be a useful thing. So you set everything up, you garbage collect every frame, so you make a pass through all the objects in your game. It's going to take discipline to make sure that none of the big things stay in the game heap. You put all of your assets, resources separately manage, but the game stuff, you have it in the heap, you can make a walk through it every frame. So it's this fairly standard sort of compacting or broken hearts, garbage collection where you pass through, you copy over the stuff that you still need to the next frame. So it takes twice as much space for your heap. But the game heap, if you isolate out all of the constant data and all of the big media, it's not that large. I can guarantee that our real mutable data, it's accounted in megs, not tens of megs, and it's probably only a few megs. So it's completely credible to walk it every frame. So you walk through the entire frame, you compact and copy it, garbage collect to another frame, but you keep the old frame there and you memory protected. And when you're fixing up all of these pointers, as you're doing that, the garbage collection, you're marking pointers on whether they're in use, whether you've copied them over. But each entity keeps its own pointers to itself. But any pointer that it has to something else points to the frame that was just memory protected, that was garbage collected from. So any pointer that you get is either going to point to your state, which is mutable, or if it's pointing to anything else, it's pointing to a static copy. So you will bus error if you try to access that. It will be hard protected. So it's not possible to sneak in something that's going to be a race condition. And I think that under those conditions, you get garbage collection, which is a programming win, you get the dethreading of all of these things that we do for performance reason. You allow it to run all of these things in parallel. So we get more scalability as we go up to dozens and dozens of cores. And I think it could be a really huge win, but it's a research project. It's not something that I can sort of roll into the current code base. But I look at it and think it's not ridiculous that it could be migrated towards. And it would have some large benefits. So that's one of my sneaky schemes for wanting to kind of move the state of the programming forward there. But there's several things that need to happen before that can really come to fruition. So some of the other things that are appealing about Lisp is one of the, so related to programming the game stuff, I have been scratching my head a little bit in recent months thinking that when I look back at Quake 1 with I did Quake C and that was me just totally winging it on language design. You know, okay, I've got C format expressions and one object type that goes across the only thing you use for all of it. And it was certainly a huge success. There were lots of people that learned programming so they could do QC and make mods for it and it's had a positive impact on the way the industry's gone and people that have gone into it. But now I really do kind of wonder what would have been the divergent road if I had made, if it had been Quake scheme instead of Quake C. Because scheme as a small version of Lisp is one of those things that the language is, it is extremely elegant and concise. And when you really sort of get that all you need is this parameter substitution in there and you could do everything from that. There's a there's a majesty to that abstraction that's pretty powerful. And it has all the damn parentheses and it has prefix notation and these things that people professional programmers that are used to working in C are not comfortable being shown a bunch of Lisp. There are arguments. I'm not sure there are statements. I'm not sure that I believe them that novice people that have never programmed before take as quickly to functional programming as declarative programming. It doesn't quite ring true to me. I think that might be some selection bias that maybe the MIT undergraduates that say they've never programmed do as well when presented a functional programming language. But there is a lot to be said for the imperative nature of you explain computer programming by you do this, you do this. If this you do this, otherwise you do that. And from teaching my seven year old, I think that it's, I think that there is a value to the imperative nature there. And I do wonder if we had had a more potent language there, if we had used something like scheme, what more could have been accomplished there that wasn't in the nature of just quakesy. And so, you know, an idle thought where for embedding, for doing a big application, I think Haskell is just a superior language for what you'll get out of it than Lisp. There were lots of times I was doing Lisp code and I was thinking this would be shorter and clearer in Haskell. And certainly the typing is a huge, huge thing. But for small things, for an embedded language like what quakesy was, there's a lot of advantage to Lisp is so, scheme at least is so tiny. You can make it very, very small and yet still have kind of complete power. You know, you can in theory do anything with even the simplest of schemes there. So using it for an embedded language is still appealing for me. And I've sort of still got my eye open for where, where could I use this in some way? Because in the end, well, I wouldn't do application development in it. I found it charming in a way that's sort of, I may be difficult to convey to especially non-programmers, but it is this very, very old language that is still as powerful as you might need it to be. It doesn't have all the sort of accoutrements that you would want in a modern development system, but it's still all there in theory and elegance. And I will probably continue to, as I carry my iPad around, it's sitting in the last airplane flight I took. I wrote a Sudoku solver in there because I was sitting there with my iPad and the Skymall magazine, whatever. So that ability to kind of do random programming at random times has been useful for me. It's taking, taking fellow hours that I would otherwise not be doing something particularly useful for. And let me do something that that's actually creative and programmer growth inducing. And so functional team wise. The idea of it's obviously not possible for me to go and say, okay, everyone did, we're going to work in Haskell now. This would just be not good for all sorts of reasons. I know you want people to work with the tools that they're comfortable with. And that's actually something that's been challenging for it specifically in recent years and that we have, there is an industry way of doing things. And there are zillions of people that are just pieces that, unreal and unity that have skill sets that are hard one and working to something that's a very different paradigm, different way of doing things, different tools. There is value lost to the world when you take somebody that's expert in one thing and make them be a novice in something else. There's also the upside from that where when I was going on about Haskell, I had one of the developers that Ian obviously went and looked into it and he came into my office with this sort of cross look on his face and he's like, what the heck is all this Monad crap? And I sort of understand that where if you take somebody that knows how to program and you say if you take a person that knows how to program and see and you say, well, here's Python or Pearl and you look up the correspondences. Okay, here's how you get the time, here's how you call functions, here's how you deal with the file system and it's just a matter of translating what you know into another language. What's going to functional programming is a different thing and to get the most about it out of it, you have to sort of embrace newbie brain. You have to be able to sit back and say, I'm not an expert, I'm not a master of my domain, I'm going to go back and I'm going to learn something that's fascinating that I don't understand and I'm going to be groping around for a while not knowing what I'm doing, but in the end there may be some insights out of it, but you can't drag a whole company into that. And what I'd love to see somebody doing is I do think there are real benefits to it and the Haskell ecosystem is improving, there are some companies using it for commercial work, but it's still not industry grade. But I think that there's a great opportunity for a team if you've got a small cohesive team to be the functional programming team and figure out how to make mobile games or make web games or do things that you can iterate on that you can do these six month project cycles to to learn the lessons and the things that we learned 20 years ago with the development systems that we use now. And there's an opportunity I think for that goes on for years of evolution. People do things hopefully keep their heads above water, I, you know, land the contracts or sell enough of the different things, but evolve to the point where you've got a team of ace people that can then take on a big challenging, important, valuable project. When you are ready to write millions of lines of Haskell code, you don't want to go into that blind, you want to bootstrap it up through a number of small projects. And there's no amount of seminars and exercises and learning that you can get to that without going through the project. You know, the whole project cycle of starting it out, having your missteps figuring out where you went wrong, correcting, releasing, post mortemying and going through all of that. So I hope there are some groups out there that are doing just that, that are core people probably from college that are, you know, that are into functional programming, go out, do valuable things, build the skill sets and turn into something powerful, something that we can look at five years down the road and say, and they are just kicking everybody's ass because they're, they made some right decisions early on and have, you know, built up the skills necessary to do that. And I guess that's probably about it. So I'm not too far off time. So I'll take, I'll take questions now for as long as anybody wants. So do we have a microphone that I can get out into the audience? Yeah. Do we have microphone? Anyone here? Okay. You can yell really loud. On Sagan. Yeah. So I, it was interesting a couple of weeks ago. I was trading some email with Elon Musk from SpaceX and I was talking about some, like, I'm excited about these virtual reality things and other stuff. And then he kind of hits me with this, you know, well, if it's not on the path towards colonizing Mars or making the money to fund colonizing of Mars, you know, it's just not, not that important. He's like, making me feel guilty for not thinking about a planetary scale. I, and yes, Elon is serious about all that and I respect the hell out of him on a whole lot of levels. I, so earlier this year we crashed the last rocket from Armadillo and I did spin down most of the development work for this year. We're talking to some investors, different things right now, but I, I made the play two years ago that I was going to, going to go for it for what we thought Armadillo needed. We thought that we were within striking distance of the suborbital cargo markets. The NASA, the NASA cruiser payloads. And there were a lot of people interested in working with that. You know, we're working with the, you know, we flew payloads from people at the European Space Agency and the universities locally. And it looked like it was achievable there that there was enough market to, to make the business case close. But we, the state that we had been in, we got to the point where we were scraping by, I mean, we had an operating profit, but it was doing contract work for, for other people. And I reached the conclusion that if we just weren't going to, to get where we needed to go with that. There's this tempting thought that if you work for contracts people and you pick the right contract, you'll be developing things that you wanted to develop anyways, that it will, it will help you towards your goal. And there's companies, many companies that have taken that explicit tack. And as far as I can tell, it's not working. It wasn't working for us. We, you know, we were keeping the lights on and we were building rockets, but they weren't the tasks, the things that we needed to do. So about two years ago, I made the call that, okay, we're going to cut out all this contracting work, no more NASA or force, rocket racing, whatever. And I was just going to dig into my pocket and say, I'm going to spend what we need to on the development. I, you know, which turns out to be something north of a million dollars a year to run the, run the team. I, you know, we had eight people on the team. We have a large hanger. There's bills and materials and the operations of going out to New Mexico to fly. I, it costs a million dollars a year. Maybe we could have saved a little bit more on that. But I went into it thinking that we can do this in two years. The arguments that I would make is we had bike clockwork almost since the beginning for over a decade. We had built two new airframes a year and we learned immense amounts. It was great. You know, we would build these crazy different things. We built the manned air plane, rocket planes. And so I thought, okay, we're at this point. We have the propulsion pretty well understood. The numbers close. It looks like we can do this. We're just going to repackage the things that we're doing into these more tubular sounding rocket arrangements. And it's, it seemed like a perfectly good plan. Everything makes sense. But what happened was disappointing. And I'm still, we have arguments somewhat about exactly what, you know, what the causes of this are. But when we went to do that, what should have been faster repackaging of everything turned out slower. And we wound up, we built two airframes the first year. And then the second year we wound up only building one airframe. So things had, had regressed and we're going slower where we should have been able to turn these things out in series. We made less progress. So we got a bunch of things flown. We, we flew to 94 kilometers with, with one vehicle. We had at least one completely successful recovery with the, or one guided recovery back on the steerable parachute, which is wonderful coming down, landing the rocket in front of the pad. The individual pieces came together, but we didn't get a mission that had everything work together properly. And we were flying people's payloads on this. They were sort of like at your own risk. I, you know, you can put them up. You might get your payload back. There's a good chance we're going to crash. We had Purdue University was put a payload on practically every single rocket. And they got to learn a lot because they had cases where their stuff didn't trigger or our stuff made a smoking hole in the ground or our stuff recovered. But their stuff didn't turn on right. And we went through a lot of useful learning experiences there. But we also had some fairly expensive payloads from the European Space Agency folks that we were flying on there. And it was, they knew it was at risk and we didn't take their money when we didn't make a successful flight. But I was disappointed that it didn't, it didn't turn out better. I have a few theories on why it worked out that way. The point that I tried to avoid, it's a heuristic point is that I just, I wasn't as involved with Army to Low in recent years. I had smart guys there that I, you know, that I felt were competent, I respected their directions. But me not being there left me in the position, not wanting to second guess the boots on the ground when I, when something would come up. And I think I kind of think you should be doing something the other way. But if I'm heads down on software and they're the ones there every day working on things, I didn't feel, I didn't feel really justified. And I never want to be that manager that's out of touch with what's going on in the engineering, that's just saying, oh, back in my days we would have done it this way. So I let my hands off the wheel there. And we can't make an A, B comparison about how important that may or may not have been. But there were, you know, there were some of the things that I, I term creeping professionalism that, that came into it where in the old days at Armadillo, we were, we were all about, okay, here's an idea, run down to the shop, grab the, the saws and the welding gear, slap something on the mill and, you know, and you've got something next week and it's, it's fabulous. But I, as we did more contracting work, I, we started having, and as people got full time, we would have a big engineering drawings, lovely stuff comes off the plotter with the, I, all the information about it, we have our revision controls, you know, on the, and our document systems. And of course NASA loves seeing all this stuff. It gives everybody that's contracting a good set of warm fuzzies to get stuff you hold in your hands on the engineering documents and to know that we had a preliminary design review and all this is, this makes people feel good when they're paying for engineering, it definitely slowed us down. Some of it may also have been the, the move to full time employment where there was a, when we were all a volunteer team, when it was just me paying the bills and everybody had a full time job and we came here and we, we worked on rockets a couple days a week. Everybody was really focused on getting the work done. If you know you're, you're going to be here for five hours and here for eight hours. There's just, you know, there's not a lot of time for, I, you know, for goofing around. And we, and actually we had a little bit of that when more people, we sort of hit a critical level when we had a couple more volunteers and I noticed productivity actually dropping. We paired out some of the volunteers and productivity went back up. So there were certainly some of that effect when, when you get everybody in it's your job, you go in and you know, you check your mail and browse the web a little bit in the morning rather than going first thing down into the shop. The people that I had this thinking that, okay, people are working 20 hours a week part time and they still got a full time job. We should be able to get three times as much stuff done when everybody's full time. But it didn't work out that way at all where when rocketry was people's full time job, they got other hobbies and they did other things with their 20 hours a week on it. And then your, your 40 hours full time a week is very rarely 40, really good hours for most people. When you, you wind up having all the little things you do at work, they're not really work. So, yeah, there's a number of things that, that may have contributed. And we're still tantalizingly close. One of the bad things that we, the things that we didn't do is we should have made series production of, we should have made multiple vehicles at once. And we did this years ago with our modular vehicles. We made parts for five of them and that served us so well, you know, we, we got to crash every single one of them, but it wasn't that traumatic because we had more pieces there. We just built another one. We desperately should have done that with these two rocket vehicles. And that, that was our, that was our critical mistake in the last two years because we should have been able to put more of these together. Creeping performance was another thing where it's, we used to just make everything out of aluminum. It's not like the highest tech material, but carbon fiber started creeping into our, our development systems here. We started, you know, we started heat treating our own aluminum, rather than just using thicker aluminum and all of these other things that, and this is chapter and verse for some of the errors that NASA has done over the years. And it's heartbreaking for me to see my own team following some of these, these problems. I, but the situation we're at right now is things are, are turned down to sort of a hibernation mode where we've still got people maintaining the shop. I, we are talking to some, some other investors. If anybody wants to kick in a couple million dollars to build rockets, give me a call. But it's probably, if we don't wind up landing, you know, an investor, it'll probably stay in hibernation until there's another, you know, liquidity event where I'm, I'm comfortable throwing another million dollars a year into things. And the rocketry has always been a, it's been a negotiation with my wife, I understandively so where she's always insisted that I not be one of those celebrities that squanders all, you know, all of their fortune being high on the hill and then penniless someday. So, rocketry has always had this carved out area where this is John's crazy money. I, you know, while all of this is to make sure that, you know, the family will be well taken care of and John's not going to be begging, begging for work sometime. But I basically expended my crazy money on Armadillo. I, so I don't expect to see any, any rockets in the, the real near future. Unless, I'm, you know, unless we do wind up raising some investment money on it. Yeah. Oh, so you have a mic. Thank you. You were talking earlier about the differences in technology between CPUs, Intel and AMD. What are you seeing in your opinion between GPUs with AMD and Nvidia, with the current technologies and also can you please sign my license plate? Sure. I'll be around here after that. It's all great. Thank you. So I, I have not done side by side direct benchmarking. So you can't, I'm, you know, I can't make a definitive statement on, I, AMD or AMD versus Nvidia on the graphics card side of things. I'm, I mean, as far as I can tell, when I have looked, AMD is occasionally faster. Uh, they're hardware is certainly top notch. Uh, it has always been the, the driver and software ecosystem that's made me tend to stay within video. Uh, you know, Nvidia has had a really spectacular team there and they, and the, the AMD people are working hard, but in, Nvidia at a strategic level has just piled a lot of really powerful people onto making that software ecosystem really good. Uh, but AMD is continuing to get better. Intel is getting better on the software side of the, you know, there used to be just the, you know, the horrible, they used to be in video with good OpenGL drivers and everybody else in various levels of awful this. But now the big three of Nvidia AMD and Intel are all pretty good. We can, we can ask for better in most cases, but I, but I, I'm not unhappy with any of that. On the, on the CPU side, we did benchmark some recent AMD's for our, our cloud, our baking stuff that we do for making the megatextures, which soaks up hundreds of cores of CPU and they were still, uh, and they still lagged Intel on the, the performance standpoint a bit there. On price performance, uh, if you could throw enough cores at it, they, you know, they're arguably a win in some cases, but we wind up being sort of box limited about one day throw as many cores into one box, uh, on a lot of, we benefit from not fighting with blades versus, uh, having larger systems with dual sockets and everything. So they're doing great work. I think that I, I mean, I, I feel bad even having to make the statements about whenever I, somebody really draws me out about, okay, you know, which do you prefer? Well, you know, I do prefer Intel and Nvidia personally, but these do in great work on so many things and there's lots of cases where for, it doesn't take a large other reason to over shadow the difference in performance and value metrics that I'm looking at. It's great to see a bunch of competent people working on lots of different products. Yeah. I can't. I actually asked about whether I could say anything related to the development and the answer was no. Um, yeah. What can we can ping pong even come back to you? Yeah. So in some ways, the, I, I do, I do feel a little nostalgic sometimes for the glory days of microprocessors when I'd be happy getting my microprocessor report to hear spark versus PA risk versus power versus, you know, X86 versus arm. And now it really is X86 and arm. I mean, power PCs still there for, for the Wii U and for some embedded things, but we, it's clear that we're, we're getting into Wappily. And I always find it remarkable how Intel had the strong arm technology from deck, that, you know, when deck fell apart, Intel had the world's best arm processor for years. They did nothing with it and eventually divested it. Now all of a sudden the arm stuff is super important. I, so I would betting against Intel on an engineering basis is I, you know, a CPU engineering basis is probably really, really risky. Now, I mean, they, they don't look as invincible after sort of flubbing the Larabi stuff, but they still probably have the best guys at the circuit, you know, at the low level circuits that I layer when you're looking at things at the process level and how to get the very best out of, not some synthesize out of a bunch of RTL core logic stuff, but when you're going down saying, we're going to make the most efficient thing. They are probably better at it than anybody that's making arm processors. The, the baggage of the X86 is, is really not as much as a lot of people would think. I am, when you can look at it as, in fact, there was a, there was a lovely article that came out in this last year about the trying to analyze the, the real importance of instruction sets. I, and there was a bunch of data through there. I heard people can testing the, the results of it, but the result that was reported was that the architectural overhead of the X86 instruction set is really not that much. It's offensively ugly from a, you know, if you look at the manuals on there about how much is, is devoted to all of it, but in terms of what it costs you in terms of power and silicon, it's not that large. Now, whether X86 is going to be able to compete in a, I don't look forward to a multi-CPUR, like Android ecosystem, back to fat binaries and runtime translation, that's not a happy thing, really. I, and whether Intel would ever swallow their pride and make another arm core, I mean, they could probably make a really, really strong arm core, but that does not seem to be their plan of record. I'm pushing with Adam. I think they're going to have adoption problems with it, even when they do, probably wind up starting to win benchmarks power, power benchmarks and all that. I am, but they, they do seem committed to it. They know the, the writings on the wall, this is, this is already far more processors are sold there and eventually the rock dollar volume is going to be larger in the arm space. I mean, right now the margins are spectacular for X86, but that's not going to last because more and more things are being chewed up by the, you know, by the transition to mobile devices. Yeah. Yeah. No. Okay. We have over here. Okay. Oh, sorry. Given the two new consoles that are coming out and they're unified memory and their connection to the GPU, have you been looking at anything concerning abstract algebra, like mono-eyed semicrups concerning that parallel computing power that you now have access to with low latency? So, as far as using the GPU's for the additional processing, that's one of the things we're a little bit behind the curve on right now. We have, I did a bunch of OpenCL work a few years ago, but we are still sort of hand waving our exact strategy for how we abstract between the, you know, the different interactions for the OpenCL versus direct compute and possibly using compute shaders in different places. So we're not all sorted out right there yet. That's, I'm not completely positive how many places we're going to use it for. There are complete no brainers, like building particle systems and some of the particle system works is no brainer work for doing compute. But some of the things collision and some of the decompression stuff there benefits to be had there, but they're not as huge as you might think from the flops count. I am very excited to see how the tight interactions using shared memory, having the unified space, being able to just pass buffers around, having low latency compute job dispatches that aren't all serialized through the graphics command buffer. There's a lot to be done there and I need to write more code. I mean, it's been a few years since I wrote any compute shader things and there's more that I need to personally pick up. Yeah. I was wondering if you could talk about Intech 5 and it's been up for a few years. Has there been any big changes with the engine since Rage came out? So we're not dramatically changing anything. The fact that Wolfenstein is still cross-generational where it's still going to have a 360 PS3 excuse I meant that you can't make a super dramatic difference change in there. We are lots of things get cleaned up a little bit better. We are still pulling out some of the mine fields of things that we had to over optimize for the previous generation. It's a little bit of an awkward time as we have these titles that are are shipping on current generation hardware. The thing that I still that's been most painful about it that I still feel the most is the disk size limitation where it's if we had infinite space there would be I wouldn't feel at all bad about the decisions that we've made. We've quite to root the up the resolution in all dimensions. But we can't ship that on all the optical drives. I think that if we can wind up streaming that from the cloud to all the different platforms. There's a lot of possibilities there, but we still have a lot of discussions internally about the the winds versus the costs of static baking for some things how we couple it with dynamics. So there are continuous arguments going on. But most of the work right now is getting more physically plausible materials bringing the high dynamic range with accurate interpolation of different things. Stuff that's I've actually been for you know for a couple months now I've been sitting with the artists. I moved out of my office and just kind of plop myself down with in the middle of the art team so that I could hear them bitching and moaning about the different things and try to prioritize what you know what needs to be fixed what needs to be addressed. There's so much that has been just education. There are so many things there that that we can do a great job of if you approach it a certain way and and as we hired lots of people like I mentioned before the issue about hiring from different studios that have different technology pipelines. A lot of people just wouldn't know the right way to properly set up your environment maps for things or the right way to tune something or what should be in the different channels of the textures. So that's where most of the visual differentiation is coming out now and it has to be that way because there is push to get your latest bullet point G with Figuero G with feature of okay you need to do this this this and this to be next gen but there is so little that you can just throw additional technology at the same set of media and make a difference at right now it is not the right way to go. We do need to get to physically plausible materials for everything so that you can so the global illumination can can act properly. In range we had global illumination where you could have you could drop a nice light and it could light everything up and because it was baked we could do a high quality job on it but we had the diffuse maps if you look at the textures most of them are half or a quarter of the level that they should be so there are all these fudge factors going on where global illumination had in many maps of 5x multiplier assigned to it because if you just were just completely implausible so there is this education that has to go through and I tried to do this several years ago and it just it wasn't the right time we were too busy with rage and the other things and we had too many entrenched sort of ways of doing things but that is at least progressing now and that is our big thing much more so than any specific technology because you can't address the technology for a lot of those until you sort of get a handle on the source data and we haven't had it really sorted out. Yeah. You mentioned before that the doom franchise to you meant demons and shotguns I'm curious what the what is software means to you from the standpoint of a founder and of course long time employee. I made the comment before that I really don't think much about the past and legacy. I've commented that I'm a remarkably unsentimental person that's once brought to my attention like at quite calm it comes up and we're like look at this. It's like oh we did this 20 years ago this 18 years ago look at that and you know wasn't it cute back then with the run room at the small hotel but I don't think about it much. I'm happy I'm proud of a lot of the things that I've done over the years but I've never reached a point where I want to really sit back and reminisce about them. I have I mean just heard me talk for two hours about all these things and I'm super excited about going forward these things that I want to see happen in the coming year things that I hope I can nudge somebody into changing the way they're doing it because it'll affect me after that. It's software with what we've done it's probably still it's going to be the legacy of we invented the first person shooter. And I resisted that for a while really because I sort of had this hope that there could be other directions and things that we do early on in the if we look back to the very first projects there we went keen to Wolfenstein to Doom to Quake there was this intentional sense that we are hopping between genres because you know we want to show that we're not tied to you know to just what we've done before but in the end when things reach the scale that we're at the development team size you do kind of wind up sticking with what you're known for and you know what you've what you've done and that really is the legacy of it's software and it's certainly not a bad one I think FPSs are going to be here forever just like we've you know we will always have driving games and fighting games we will always have FPSs now and we started it so that's I'm pretty proud of that. So in the past the PC kind of drove you know gaming and the power and everything and when you came up you said you know it's kind of changing with the new consoles and everything with unified memory and all that AMD and ATI merged it that that kind of made it easier for them to kind of jump in and do the whole unified memory thing how do you see that changing as far as consoles now things are going to get simpler easier so it's more of a streamline thing versus PCs having to use proof force to do everything to compete. So in the near term it's definitely good for everybody PC console developers publishers it's good all across the board right now it will allow developers to build things in a console style one thing that this would have I never would have been thought this a couple years ago but AMD has the opportunity where it's not out of the realm of possibility that we they could expose a lower level API then OpenGL D3D that's here's all the buffers here's how you write it from a console because we already have a nice layering adding another one if there was a real value there might be something to it it's not clear to be that I think PCs will have their traditional tech up they're just going to be a lot more powerful right now you can certainly buy an outfit a more powerful PC than the next gen consoles it'd be expensive but a couple years into the timeframe you run of the mill PC will be a super set in every way to what the consoles are and in fact you'll see probably damn near the same chips in PCs and then you'll see those with more cores and higher clock rates so there as always the PC will be able to soak up a fair amount of inefficiency it'd be I guess I despair a little bit of actually banquishing the inefficiency in the PC we still win in the end just by clubbing it with more and more brute force it'd be nice from an an aesthetic sense that the inefficiency not be there but I guess I'm a little bit more at peace with it but the fact that the development of the PC and the consoles is coming closer together but both those platforms should be looking over their shoulders at mobile and web and what's you know kind of going on and driving the development issues there because those are are the things that in a larger world when you look at the billions of people playing that I you know they're not it's not an argument between PC and console it's a completely different argument and those are probably going to have the broader repercussions as we look you know five ten years down the road yeah do you think those issues can be attributed to megatexture and if not are you going to use megatexture in future ed games so the performance issues on I well I on the PC we had the disastrous driver problem and we still have driver problems that that crop up on some of that is the fault of doing something that nobody else was doing there's a there's value to doing pretty much exactly what everybody else does that's the well tested path nobody will accidentally break something that relies that everybody's doing we were clearly doing something off the beaten road with with the megatexture the continuous texture uploading all that entire pipeline of things and it you know it hit the goals that we were looking for on the consoles on the PC it should have just been superior to that but we had you know we had the disastrous driver problem which colored a lot of people's views of it and we still now occasionally have problems where rage starts running crappy on somebody's system it's still not a foregone conclusion that as it stands right now yes we are still using megatexture higher densities building with more textiles on there having more in the back that we can we can call you know call as needed even if we can't ship them necessarily but if we don't the step that I would like to take data wise and we just can't afford it on the current generation of like shipping on optical media is if we could if we could ship a diffuse map along with the the pre baked light then we have the best of both worlds we have no downsides to dynamic lights and where right now we have to just approximate them but you can also have the the full glory of the completely baked moral view and we're still not I'm trying to push more towards we have all of this but we're far from tapping out everything we can get out of it where we have some technologies for letting people map paint directly on the megatextures that never got followed up on we should be able to fix every crossing edge in in the world which is something is not at all plausible to do in any other way go ahead and stitch across every time you have two things meeting don't have that edge seam there that nothing can get rid of but actually crossfade a little support texture around it the ability where you know where we have used it with the stamping has allowed just fantastic advances in something that has no stability issues or performance issues there's big winds to be had there that we didn't make the most of and we're still trying to to make more out of them in the end when you say long term data always wins so something like megatexture will win in the end whether it's you know whether it's dominant in a coming generation or it takes all the way to the transition for cloud gaming when you look at a cloud gaming world where you're running on a data center server having it's completely credible to consider having a petabyte of data for this entire glorious world that's you know that's built with cloud resources rather than on some local farm over and over almost all cases cleverness and compression technologies eventually fall to just put the dam data there it's possible we were pushing a little bit too early on megatexture because it just barely worked on current generation stuff but I think inevitably that's where things will be your tiling textures is just a very peculiar form of texture compression and you you expect to be able to have your entire surface spread out and boy I really want to be able to reference the surfaces as direct 3D coordinates whether it's you know some kind of voxelization or something but I hate unwrapping and pelting things and adding gutters around it and all the issues that that adds to us but eventually you just want the materials of the world what what it makes up and it's going to be something like a megatexture on the topic of virtual reality and strapping a display to your head pretty much what's your opinion on doing something with pulling in input from the outside and doing something like dual google glass and having augmented actual 3D augmented reality okay so google glass and augmented reality in general the vision there is that you've got you know terminator vision where you've got text appearing in front of everything you know that flowing people's names over their heads and that's going to be huge that is going to be a many many billion dollar industry it's going to I think take over the way smartphones have I think that when that finally becomes real five years will go by and everybody will have augmented reality goggles now it's important to realize that what google glass is today is not that vision at all it's a tiny little cell phone screen in your field of view I and there are way hard problems involved in doing the the vision of augmented reality about outlining people and floating things and chain you know adding solid objects into the world and hey brush and his team at valve spent you know quite a bit of effort on it and I was pushing them really hard like VR we can do today we can make this awesome we can make a difference and it'll be spectacular the AR stuff it's going to be a bigger deal than VR eventually but I don't think there's any guarantee that eventually is even going to start five years from now I think we're going to see a lot more wearable stuff it'll be the built in cameras it'll be the little info screens what google glass is today will productize and will be valuable but the game world and what you imagine that about I want to put virtual people into those seats you know I want to you know I want to have the crater open up in the floor in front of me that's not coming in the real near future eventually it will but there are many hard problems to be solved before we get there but the VR stuff's coming soon and fast and it's going to be great great yeah so when we look at like the future of voxels versus ray tracing just if you could elaborate on that a little bit you know do you think the idea of the infinite detail engine even though that's largely like procedural do you think that would be maybe a stepping stone to ray tracing as you know poly counts increase or really do you think that's not even going to be considered in the future as ray tracing technologies meet performance expectations all right so eventually ray tracing will win I think that that's a it's winning in all the offline space and for all the same reasons it will win in software I are in real time applications but we still have there's a lot of leg room still for rasterization especially as we look at mobile and lower power constraints it was actually I was stunned to find that I got disclosed on caustic graphics technology which is imagination technologies bought them they're one of the mobile companies and I've I've looked at three or four ray tracing architectures over the years that have all been hopelessly naive it's somebody that either knows enough about hardware to you know build some form of a ray intersection engine and things oh we can use this for games with not understanding any of the many manifold issues that are involved with it but the I the caustic stuff is is smart they've got some I was one of those where I learned a couple things reading through there I their technology paper that it's still not obvious to me that it's going to be a that it's going to make games productized in this generation I I don't think it closes on that you can do a real time ray tracing game but it's hard to show how it's going to be better than a rasterized game my pitch to them is if you know something that would be unique on there is you should do a a jewel retool a kind of like a a super bid you old because that's the one thing where you really do care about your index of refraction and your colors on there that would be the perfect poster child case for for a ray trace chip as you can do this awesome jewelry tool and be jeweled is sold a heck of a lot of copies so that might even drive adoption of it I'm but getting your foot in the door with something as a way to once you're there you can evolve and you can get better and you can eventually start encroaching on the the standard graphics territories I'm and the reason why ray tracing is going to win is because it is understandable and tunable I'm the you know there's the the great comment that somebody had on Twitter about looking at this 800 page book on shadows for GPUs and you know there's basically saying if you need this to do shadows you're doing it wrong because in ray tracing all you do is you distribute points to the area source of your light and you you trade off where you put them and how many you do but it's simple it's it's a loop this big to make all of you know all of your shadow calculations basically and simplicity has a lot of value there's the lesson of the year really or of the age as we're going into is that the things that we do we would do for optimal performance previously are many of them are ready to be traded away better understandability robustness developer predictability and so on I so voxels and in terms of other representations of things it still it still seems on the aesthetic to me that we're ray tracing against triangle representations I but it seems like it's going to get good enough like it's going to win and whether you're tracing it's to triangle or some kind of meta blob splat thing it's at most a linear difference in performance so it's not large and I was I would have been surprised years ago to think that some form of ray tracing and it does wind up all being against triangles I thought that there would be something else I that there would have been large enough benefits but it's not looking that way now these it comes back to the tyranny of the pipeline we have everybody knows how to make these triangle meshes now but if we go to say well now we need to build some kind of voxel thing they'd still be making triangle messages that we voxelize at some point which is then sort of going through this additional media transition transition and if you had the ability to just use the triangles I am but an interesting thing about when you do look at the triangles now it's crazy the performance that we have on GPUs that you can load up 20 million triangle models and big work yes it's fabulous when you think about it but what's surprising is how bad many of them look if they're I if you've got any vertex operations going on whether it's vertex specular shading when you've got 20 million triangles and you're drawing it on a 2 million pixel screen the triangles are just randomly coming and going and there are significant additional aliasing anti aliasing challenges to be had there do you love one thing that I've heard you mentioned for a while is um AMD's virtualized texturing what is your views on it are you would you consider incorporating into a tech five-made for future games or anyway so we've been working with that quite a bit and we were obviously the implementation test for the extensions going going into it it's I think it's I've been pushed that had been my crusade for a decade to have virtualization of these different things and it's I it turns out that the nitpicky details about page replacement and especially feedback from it is harder than I would have thought 10 years ago you basically wind up having to almost implement the the tech five feedback buffer sort of thing with all that messy stuff I do wish that there was an ability to just have it demand page to say back this by my flash drive I think that that would be a big step forward but that involves interacting with the operating system I think it's about as good as it we we were vetted on the extension we were part of the specification process for it and it works yeah it gives us some real benefits in that we can get proper anisotropic trilinear filtering with a single with without having to go through our megatexture pipeline for all these different samples um so it adds some benefits it's surprisingly not quite as much of a huge wind as we think considering how much code we do on the megatexture side of things already the biggest benefit will probably be from letting us take advantage of all the memory space in certainly the consoles it's unclear how much the PC where we want to be able to just say okay we've got this many gigs we're just going to let our let our pages fill up everything where right now we say you've either got a set of 4k or 8k textures and this will give us flexibility to just take up however much we want and there's still the trade-off that we have to make between how much space do we set aside for our compressed cache where it's all I you know DCT or HD photo compressed at a very very high bit rates versus how much do we set aside for direct access by the virtual textures and one of the things that I'd love to do is and it's not clear whether this is going to be feasible even on the current generation is I'd like to not have I'd like to use uncompressed textures for everything if it means less pages but we can have we can at least take advantage of more memory there but one of the problems right now is that we use a ycsg color space which we convert to RGB before we do our calculations but you can't apply gamma correct texture filtering to a ycsg since it's zero it's biased into the middle I'm I'd like to be able to just use uncompressed 888 RGB for the stuff so that I could use I could get gamma correct texture filtering be proper throughout the whole thing but that's a lot of extra memory here looking at going from 8 bits per pixel to at least 24 if not 32 if we don't pack anything else but that's where we look at those things at the memory we've got all this memory I don't know what we're going to wind up blowing it on we always wind up out of memory in the end it seems inevitable but getting rid of some of the compression artifacts there seems like it would be a positive thing um this past generation with the consoles then one one of the longest ones we've had in recent history do you think that it will this new generation with the ps4 and the xbox one will last as long as this past the console generation and will it integrate augmented reality and virtual reality so I think that it will last at least as long I'm well there's a couple arguments that could be made I don't think it's going to be supplanted by a different architecture in that same time frame now whether the platform can evolve is another question they are getting more operating system like in the way you interact with them we don't get to you know get our grubby fingers on the bits anymore even on the consoles I'm sure there are strategies for evolving the platform as we go forward but I don't think there's going to be much of a push for another generation for a long time really we could be doing great innovative work even on the current generation for many more years yet it's not like anybody's seen everything that you can do if you take as a challenge well but I really want to do real-time global illumination at 60 frames per second I can't do that when me on the current console yeah you can say we need new generations but if we're concentrating on you know on making great games I don't think that you know I'll be surprised if we see radically better games enabled because of the new capabilities on the consoles and I thought for a while we're at our past the near the curve and the payoff benefit so we're going to be definitely on the the gradual sloping part of it going forward so I don't think that there's going to be a push for you know maybe we get to the radical ray tracing platform at some point that's it's probably not worth changing off until we get to that point but whether we get something like cloud gaming owning large shares of the market before then or people using mobile systems where you just play on your mobile phone it shows up on whatever screens near you that could become dominant gaming platforms but a traditional next Xbox yeah I think that's a long ways off and it there's a credible argument to be made that there there may not be another console generation as we know it now but don't know yeah do you think that the performance of non-volatile memory like SSDs and whatnot could ever reach a level to work could be combined with system RAM and if so how much simpler would that make everything for you so SSDs have been the greatest performance thing that's happened in recent years much more so than multicore has been for us the the difference that you get when you move to an all SSD system it feels like the good old days when you just doubled the clock speed on your processor like wow my computer's really fast I so that's been a really great thing and I think an interesting thing that we've seen is while it's easy to say we'll always suck up whatever resources are available and I just you know said that a moment ago but what's been interesting to see is while there are definitely exponential trends they don't have the same factor on them I we are seeing clearly that people don't fill up their hard drives and people are able to migrate to smaller SSDs so I think that's a good thing and having there's something to be said for the silent PC as well that you know we don't have these big leaf blower fan fans on things anymore it's it's nice to see something with no fans no air mover's maybe it's not as powerful but it's not getting hot it's not you know requiring to be blown across there so SSDs have been really good now what will happen in terms of integrating it like more directly with the system I think that there's a clear path to that and that's this embracing memory mapped data structures where there is a big benefit to doing that from a stability standpoint when you actually use memory protection and you say this can't be touched we say all right we're you know looking towards the future we've got 100 gigs of something that we're going to just sort of have mapped here referenced and whether it's backed by some combination of cash SSD going to hard drives going to the internet or dropping the hard drive in between and just cloud to to SSD there's I I think that that's a clear and obvious direction but it still requires getting the OS and the GPU people together but I think that's going to have big payoffs you can't just say well I'm going to take my latest AAA game map everything there and have it run great but the thing is it'll actually run better than most people I think would credit if you did no optimization work on that and if you just do a little bit of pre-fetching for setup I think that it will be an improvement because it'll make software better it'll let people build games without having to worry about how you're marshalling your data around I think it'll be an improvement in a number of dimensions. Thanks for humoring us and staying here for two hours I really appreciate it. I was just wondering about your thoughts about strobe lighting and how that affects motion blur current LCD technology. Okay so the valves low persistence demo is a global global shutter so it strobes the entire screen and interestingly they think they've identified some other perceptual issues with that where you know they think that when your eye makes a very fast scod that if it's going from a point where maybe there was no illumination there's a perceptual thing that they're fighting. The other way of doing temporary illumination is with a rolling shutter where you like you're drawing the scan and it can be blanked out some distance behind instead of overlapping and continuously being illuminated you have maybe a quarter of the screen as a bright band going down. I have a theory that I'd like to see applied to this where instead of linearly addressing the frame buffer in a standard scan pattern if we went to a deep inner leave pattern say eight or sixteen wide inner leaving where you're getting scan line here here and here and here and here and here and they're blanking out 16 or however many scan lines attempt at the frame behind. I think that might have a useful benefit there where you could be at no point would any part of the screen be black you would be within say 16 pixels of a lit line so perhaps that'll alleviate some of those perceptual issues and you could also then look at it as a thousand frames per second display that's very sparsely set out and you could go ahead and render a thousand unique frames or do the time warping thing to that and that's probably the best way to wind up doing this but the fallback plan sort of plan B is LCD backlight issues where the current light boost technologies on the the Nvidia light boost monitors that the high at Asus ones they do a remarkably good job at this where they they flash the backlight for four milliseconds then they turn it off while the actual LCD is updating then they flash it on for the alternate eye and while this was designed to make 3D gaming work better to have the glasses work better but it's a really good thing for any dynamic fast motion thing as long as you're updating at that 120 hertz if you're updating at 60 and you're double flashing it's got this weird artifact to it that's perceptual if you look at an high speed camera it's it's doing exactly what it's supposed to but if you update 120 times a second with those blankings it's better than you know than any normal 120 hertz monitor I that's still a global strobe so the alternate approach is and I know I've seen somebody online doing the homebrew project with a string of LEDs that they're strobing in order I to do that and that's that's a that's a valid direction to go that it can work even with slow switching LCDs because if you have an LCD panel that takes 15 milliseconds to switch and there's a lot of them there are more than that like the current rift one takes over 20 milliseconds to switch and some of them are even worse but if you're down to 15 if you're over 15 they're your screwed there's no way you can get the low persistence down but even if you're at 15 you could have your scanning in changing the LCDs I but it flashes it just before it's going to change and it goes through so you're flashing what's 15 milliseconds had time to settle there and then it goes on and then you can flash the next bar and turn that one off while it's just starting to do its long change period so I think that's that's plan B for head mount display technologies if you can't get awesome fast switching OLEDs on it which would be the OLEDs are the best way to go if we can get that that's what we want I'm failing that the LCDs with a strobing backlight but the problem is LCDs are getting so tightly integrated that in the old days your backlight was this separate assembly that you could just like take some screws off and pull it off and look at your transparent LCD which is pretty cool but now everything is these laminated packs of super high technology and getting you know getting into there to be able to strobe them is is an open challenge and whether head mount displays will ever be a large enough market to make an LCD manufacturer make some change like that when they're talking about millions and millions of mobile phones or other mobile devices I don't think you know it'd be it'd be great if the head mount display market had that kind of clout in a couple years but I wouldn't hold my breath for it you talked earlier about some of the issues with control devices what do you think are some advancements to be made in that field in the near future so control devices I think that the near-term pragmatic things are going to to be a split controller whether it's like a hider or two moves where you've got motion and buttons and position tracking full body tracking things like the the leap gesture tracking I think those are going to have value but it's kind of got the no button mouse problem with the connect and you start having to do gestures to trigger things which becomes this very imprecise direction so I don't I don't have a wish list like on the output side on display technology I know exactly what I want I don't have that so much on the input side if anything I've got low expectations where I'd be thrilled to just get a great position sensor a position sensor that had accuracy repeatability no drift I that would that would make me super happy and it still seems to me that while the action does seem to be in optical I am continually amazed by the fact that RTK real-time kinematic GPS systems can give millimeter level relative positioning from GPS satellites and these are going eight kilometers per second up in space you know multiple ones and you're getting millimeter level changes in distance that's magic you know the fact that that can be happening and that we can't do better than that on a desktop with like some really loud carrier wave emitters and placed down I still you know I've gotten fallback research that I I want to I'm trying to draft one of the one of the armadillo guys it's an electrical engineer into working working up some prototyping stuff on that but yeah there's there's camps and the optical stuff is certainly the one that's working best right now but it's still not a solved thing you still have to deal with occlusion issues and stray light reflections all sorts of other problems it can be there but the optical stuff's looking pretty good yeah we know that as technologies become cheaper and the capabilities have been an individual grow that eventually indie indie games will be able to craft experiences similar to AAA games I have two questions related to this first off how far into future how far off are we from indie games like a just a single person being able to craft a similar experience to call of duty mongwor for three and what do you think this spells the doom of the AAA AAA game industry or do you think they'll find another niche I I disagree with your premise the the AAA games are their the result of an army of people I'm doing their work and it's not programming me programming is one of the you know one of the tent poles there but most of the work is in content creation and all the technology in the world doesn't suddenly turn you into an awesome sculptor I now you can look at things like open asset libraries can start having a really really big benefit there and that's where more so than the pace of technology the change in an ecosystem like that is what you know what you should be hoping for to to advance the state of small scale development I'm and there's plenty of possibilities there when you look at what's happened with the open things when you look at the magic of the web and how androids taking off things that can be done broadly distributed for free I can have huge impacts they can have really large effects on things I but no technology is not going to all of a sudden let you let you produce a AAA game we can hope more and more stuff gets open source that I you know that when you can just and a lot of games like mobile games are done like that now where you grab a grab a physics engine over here you grab a rendering engine from over here and that's going to continue and that's going to get better and better and it's remarkable what people can do in the mobile space by cobbling things together there but it's not going to take you to modern warfare it took you to a different place and then and that's that's really great that it worked out this way because the cobbled together stuff didn't take you to quake three it took you to angry birds and cut the rope and these other things that are different and that led these developers that nobody knew about to become titans in their industry I think that there's going to be a similar thing with virtual reality I think that the people are going to do the the same type of thing it's not going to be the big companies that that sort of set the language that other people work within later on but programmers today we do have the resources at our disposal both hardware wise and what we have available in the open source world to be magicians you know you can call forth the powers of all of these different things and very much like fantasia though most of the wizards don't know what they're doing they call forth powers beyond their can and I but it still works out more often than not so it's a it's a good happy thing so I got the better wrap up soon so any any last important questions back there yeah so now that thank-go-wokes as you use it tech five how has it been how's the experience been with an Asian developer like you guys haven't worked with an Eastern team before and that's another question the modding scene do you see a tech five being thrown by it software like to something like you decay like do you foresee taking a tech fight to that level or is it going to be on a per game basis the studio decides that they'd once to do modding tools or not so we've had we had a lot less interaction with tango than we had with machine games I they started off changing the the technology more radically at the beginning they they had a lot of different things they wanted to integrate I mean there you know their quality people obviously and their their got work that's come along but we just you know I had almost I've had almost no interaction with them honestly some of the other people on the core tech team have have done more support but they've pretty much done things all on their own I you know we're deep involved in Wolfenstein at this point I'm getting everything sort of together in the push towards shipping but tango has been sort of off on their own largely I'm regarding modibility and things that's some of our major internal directions are are working on improving that because we you know we totally fumble that this generation and I don't think that I don't think it's likely that we can expect radical improvements in this current crop and like Wolfenstein and tango hopefully better but there's still there's work that needs to be done on a on a corporate level and how we prioritize things in our games how we prioritize our releases that effort needs to be expended on but that I think that I talked about doing user interface work for six months that it was my contribution towards how we're changing this going forward but it's not a near term thing and there's other significant technology things that I want to change that will be better for us and also better for enabling the you know the external creativity so I think I'll wrap it up now but I'll I'll mill around for a little bit afterwards